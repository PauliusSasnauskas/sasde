{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import jax.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util.interfaces import Config, EqInfo, Hyperparameters, VarInfo\n",
    "from main import run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eulerâ€“Tricomi equation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\displaystyle\n",
    "x^2 \\frac{d^2u}{dx^2} + y^2 \\frac{d^2u}{dy^2} = 0\n",
    "$\n",
    "\n",
    "$ \\displaystyle\n",
    "u(x, y) = \\sin(x)\\text{, where }y = x^2\n",
    "\\\\ \\displaystyle\n",
    "u(0, y) = y^2\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "  eq = EqInfo(\n",
    "    name = 'u',\n",
    "    function = lambda s: s.x**2 * s.d2udx2 + s.y**2 * s.d2udy2,\n",
    "  ),\n",
    "  vars = {\n",
    "    'x': VarInfo(bounds=(0, 2)),\n",
    "    'y': VarInfo(bounds=(0, 2)),\n",
    "  },\n",
    "  conditions = [\n",
    "    (1., lambda s: s.u.subs(s.y, s.x**2) - sp.sin(s.x)),\n",
    "    (1., lambda s: s.u.subs(s.x, 0) - s.y**2),\n",
    "  ],\n",
    "  preoperations = [\n",
    "    lambda x, y: 0,\n",
    "    lambda x, y: 1,\n",
    "    lambda x, y: x,\n",
    "    lambda x, y: y,\n",
    "    lambda x, y: x + y,\n",
    "    lambda x, y: x * y,\n",
    "  ],\n",
    "  operations = [\n",
    "    lambda z, _: 0,\n",
    "    lambda z, _: 1,\n",
    "    lambda z, _: z,\n",
    "    lambda z, _: -z,\n",
    "    lambda z, s: z * s.x,\n",
    "    lambda z, s: z * s.y,\n",
    "    lambda z, _: sp.exp(z),\n",
    "    lambda z, _: sp.sin(z),\n",
    "  ],\n",
    "  hyperparameters = Hyperparameters(\n",
    "    lr = 0.002,\n",
    "    penalty = 1,\n",
    "    nodecount = 5,\n",
    "  ),\n",
    "  epochs = 256,\n",
    "  samples = 512,\n",
    "  batchsize = 128,\n",
    "  verbosity = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:42:43.906 [INFO] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "14:42:43.907 [INFO] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "14:42:43.910 [INFO] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "14:42:43.911 [INFO] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "14:42:44.290 [INFO] Constructed symbolic model\n",
      "14:42:48.246 [INFO] Constructed loss equation\n",
      "14:42:54.170 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:42:59.214 [INFO] Epoch: 1, Loss: 13.2080116272\n",
      "14:42:59.857 [INFO] Epoch: 10, Loss: 5.1320028305\n",
      "14:43:00.620 [INFO] Epoch: 20, Loss: 2.3169665337\n",
      "14:43:01.394 [INFO] Epoch: 30, Loss: 1.6759681702\n",
      "14:43:02.182 [INFO] Epoch: 40, Loss: 1.6767089367\n",
      "14:43:02.994 [INFO] Epoch: 50, Loss: 1.5611019135\n",
      "14:43:03.794 [INFO] Epoch: 60, Loss: 1.2229549885\n",
      "14:43:04.609 [INFO] Epoch: 70, Loss: 1.0835150480\n",
      "14:43:05.442 [INFO] Epoch: 80, Loss: 1.0089960098\n",
      "14:43:06.260 [INFO] Epoch: 90, Loss: 0.9185363650\n",
      "14:43:07.910 [INFO] Epoch: 100, Loss: 0.7504286766\n",
      "14:43:07.934 [INFO] Epoch: 110, Loss: 0.7380348444\n",
      "14:43:08.779 [INFO] Epoch: 120, Loss: 0.7091070414\n",
      "14:43:09.619 [INFO] Epoch: 130, Loss: 0.6340438724\n",
      "14:43:10.473 [INFO] Epoch: 140, Loss: 0.6456730962\n",
      "14:43:11.325 [INFO] Epoch: 150, Loss: 0.5933840871\n",
      "14:43:12.196 [INFO] Epoch: 160, Loss: 0.5570219755\n",
      "14:43:13.490 [INFO] Epoch: 170, Loss: 0.5356505513\n",
      "14:43:13.909 [INFO] Epoch: 180, Loss: 0.5364072919\n",
      "14:43:14.798 [INFO] Epoch: 190, Loss: 0.4929373860\n",
      "14:43:15.721 [INFO] Epoch: 200, Loss: 0.4587530494\n",
      "14:43:16.641 [INFO] Epoch: 210, Loss: 0.4894348681\n",
      "14:43:17.495 [INFO] Epoch: 220, Loss: 0.4726893604\n",
      "14:43:18.336 [INFO] Epoch: 230, Loss: 0.3911947608\n",
      "14:43:19.332 [INFO] Epoch: 240, Loss: 0.3837181330\n",
      "14:43:20.225 [INFO] Epoch: 250, Loss: 0.4143280387\n",
      "14:43:20.758 [INFO] Epoch: 256, Loss: 0.3884317279\n",
      "14:43:20.760 [INFO] Pruning weights (1 / 62)\n",
      "14:43:20.842 [INFO] Shed -0.006371370051056147 weight\n",
      "14:43:21.260 [INFO] Constructed symbolic model\n",
      "14:43:24.683 [INFO] Constructed loss equation\n",
      "14:43:29.939 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:43:34.169 [INFO] Epoch: 1, Loss: 0.5257282257\n",
      "14:43:34.358 [INFO] Epoch: 10, Loss: 0.4170118570\n",
      "14:43:34.553 [INFO] Epoch: 20, Loss: 0.3804287314\n",
      "14:43:34.776 [INFO] Epoch: 30, Loss: 0.3445779681\n",
      "14:43:35.150 [INFO] Epoch: 40, Loss: 0.3144613802\n",
      "14:43:35.242 [INFO] Epoch: 50, Loss: 0.3166710436\n",
      "14:43:35.469 [INFO] Epoch: 60, Loss: 0.2772093713\n",
      "14:43:35.720 [INFO] Epoch: 70, Loss: 0.2857662141\n",
      "14:43:35.990 [INFO] Epoch: 80, Loss: 0.3021025062\n",
      "14:43:36.244 [INFO] Epoch: 90, Loss: 0.2703609169\n",
      "14:43:36.452 [INFO] Epoch: 100, Loss: 0.2842158675\n",
      "14:43:36.665 [INFO] Epoch: 110, Loss: 0.2783825397\n",
      "14:43:36.888 [INFO] Epoch: 120, Loss: 0.2638475299\n",
      "14:43:37.152 [INFO] Epoch: 130, Loss: 0.2642158270\n",
      "14:43:37.376 [INFO] Epoch: 140, Loss: 0.2818992138\n",
      "14:43:37.638 [INFO] Epoch: 150, Loss: 0.2681494951\n",
      "14:43:37.884 [INFO] Epoch: 160, Loss: 0.2395946085\n",
      "14:43:38.112 [INFO] Epoch: 170, Loss: 0.2491435856\n",
      "14:43:38.334 [INFO] Epoch: 180, Loss: 0.2420928031\n",
      "14:43:38.560 [INFO] Epoch: 190, Loss: 0.2537122369\n",
      "14:43:38.842 [INFO] Epoch: 200, Loss: 0.2210268676\n",
      "14:43:39.630 [INFO] Epoch: 210, Loss: 0.2503245771\n",
      "14:43:39.307 [INFO] Epoch: 220, Loss: 0.2322620153\n",
      "14:43:39.542 [INFO] Epoch: 230, Loss: 0.2269148827\n",
      "14:43:39.772 [INFO] Epoch: 240, Loss: 0.2403420806\n",
      "14:43:40.600 [INFO] Epoch: 250, Loss: 0.2380149364\n",
      "14:43:40.149 [INFO] Epoch: 256, Loss: 0.2423763871\n",
      "14:43:40.150 [INFO] Pruning weights (2 / 62)\n",
      "14:43:40.235 [INFO] Shed -2.6238179998472333e-05 weight\n",
      "14:43:40.390 [INFO] Constructed symbolic model\n",
      "14:43:43.348 [INFO] Constructed loss equation\n",
      "14:43:47.614 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:43:52.218 [INFO] Epoch: 1, Loss: 0.3678524792\n",
      "14:43:52.406 [INFO] Epoch: 10, Loss: 0.2226533592\n",
      "14:43:52.639 [INFO] Epoch: 20, Loss: 0.2992820144\n",
      "14:43:52.870 [INFO] Epoch: 30, Loss: 0.2528097034\n",
      "14:43:53.103 [INFO] Epoch: 40, Loss: 0.2406248450\n",
      "14:43:53.341 [INFO] Epoch: 50, Loss: 0.2176756561\n",
      "14:43:53.599 [INFO] Epoch: 60, Loss: 0.2503351569\n",
      "14:43:53.838 [INFO] Epoch: 70, Loss: 0.2129020244\n",
      "14:43:54.730 [INFO] Epoch: 80, Loss: 0.2223996073\n",
      "14:43:54.301 [INFO] Epoch: 90, Loss: 0.2291164249\n",
      "14:43:54.521 [INFO] Epoch: 100, Loss: 0.2031276822\n",
      "14:43:54.737 [INFO] Epoch: 110, Loss: 0.1967613995\n",
      "14:43:54.956 [INFO] Epoch: 120, Loss: 0.2071251571\n",
      "14:43:55.181 [INFO] Epoch: 130, Loss: 0.1974999160\n",
      "14:43:55.406 [INFO] Epoch: 140, Loss: 0.1948584616\n",
      "14:43:55.628 [INFO] Epoch: 150, Loss: 0.1854827702\n",
      "14:43:55.855 [INFO] Epoch: 160, Loss: 0.1795485467\n",
      "14:43:56.471 [INFO] Epoch: 170, Loss: 0.1783937514\n",
      "14:43:56.724 [INFO] Epoch: 180, Loss: 0.1715490222\n",
      "14:43:56.957 [INFO] Epoch: 190, Loss: 0.1781936884\n",
      "14:43:57.177 [INFO] Epoch: 200, Loss: 0.1667476892\n",
      "14:43:57.413 [INFO] Epoch: 210, Loss: 0.1703064740\n",
      "14:43:57.631 [INFO] Epoch: 220, Loss: 0.1633509248\n",
      "14:43:57.859 [INFO] Epoch: 230, Loss: 0.1654155552\n",
      "14:43:58.830 [INFO] Epoch: 240, Loss: 0.1678102911\n",
      "14:43:58.310 [INFO] Epoch: 250, Loss: 0.1718480885\n",
      "14:43:58.449 [INFO] Epoch: 256, Loss: 0.1770646274\n",
      "14:43:58.450 [INFO] Pruning weights (3 / 62)\n",
      "14:43:58.531 [INFO] Shed 0.07593591511249542 weight\n",
      "14:43:58.687 [INFO] Constructed symbolic model\n",
      "14:44:00.261 [INFO] Constructed loss equation\n",
      "14:44:02.597 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:44:06.568 [INFO] Epoch: 1, Loss: 0.2840245068\n",
      "14:44:06.765 [INFO] Epoch: 10, Loss: 0.1771365255\n",
      "14:44:06.986 [INFO] Epoch: 20, Loss: 0.1793256402\n",
      "14:44:07.210 [INFO] Epoch: 30, Loss: 0.1767148972\n",
      "14:44:07.457 [INFO] Epoch: 40, Loss: 0.1893598437\n",
      "14:44:07.684 [INFO] Epoch: 50, Loss: 0.1788627058\n",
      "14:44:07.911 [INFO] Epoch: 60, Loss: 0.1789422035\n",
      "14:44:08.141 [INFO] Epoch: 70, Loss: 0.1771951169\n",
      "14:44:08.373 [INFO] Epoch: 80, Loss: 0.1789670140\n",
      "14:44:08.620 [INFO] Epoch: 90, Loss: 0.1663354039\n",
      "14:44:08.830 [INFO] Epoch: 100, Loss: 0.1750650257\n",
      "14:44:09.400 [INFO] Epoch: 110, Loss: 0.1753306538\n",
      "14:44:09.251 [INFO] Epoch: 120, Loss: 0.1785828769\n",
      "14:44:09.459 [INFO] Epoch: 130, Loss: 0.1783937514\n",
      "14:44:09.669 [INFO] Epoch: 140, Loss: 0.1698318720\n",
      "14:44:09.875 [INFO] Epoch: 150, Loss: 0.1688829362\n",
      "14:44:10.900 [INFO] Epoch: 160, Loss: 0.1739196479\n",
      "14:44:10.302 [INFO] Epoch: 170, Loss: 0.1621026695\n",
      "14:44:10.548 [INFO] Epoch: 180, Loss: 0.1572140604\n",
      "14:44:10.767 [INFO] Epoch: 190, Loss: 0.1640137136\n",
      "14:44:10.974 [INFO] Epoch: 200, Loss: 0.1657510698\n",
      "14:44:11.210 [INFO] Epoch: 210, Loss: 0.1604276448\n",
      "14:44:11.444 [INFO] Epoch: 220, Loss: 0.1544878185\n",
      "14:44:11.679 [INFO] Epoch: 230, Loss: 0.1685224921\n",
      "14:44:11.907 [INFO] Epoch: 240, Loss: 0.1488464624\n",
      "14:44:12.164 [INFO] Epoch: 250, Loss: 0.1507322937\n",
      "14:44:12.303 [INFO] Epoch: 256, Loss: 0.1544127762\n",
      "14:44:12.303 [INFO] Pruning weights (4 / 62)\n",
      "14:44:12.388 [INFO] Shed 0.1657472401857376 weight\n",
      "14:44:12.528 [INFO] Constructed symbolic model\n",
      "14:44:13.770 [INFO] Constructed loss equation\n",
      "14:44:16.119 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:44:20.394 [INFO] Epoch: 1, Loss: 1.0499593019\n",
      "14:44:20.592 [INFO] Epoch: 10, Loss: 0.2005504668\n",
      "14:44:20.811 [INFO] Epoch: 20, Loss: 0.1807227582\n",
      "14:44:21.260 [INFO] Epoch: 30, Loss: 0.1669788808\n",
      "14:44:21.240 [INFO] Epoch: 40, Loss: 0.1551007926\n",
      "14:44:21.440 [INFO] Epoch: 50, Loss: 0.1570363343\n",
      "14:44:21.647 [INFO] Epoch: 60, Loss: 0.1494525820\n",
      "14:44:21.850 [INFO] Epoch: 70, Loss: 0.1630057991\n",
      "14:44:22.520 [INFO] Epoch: 80, Loss: 0.1580210626\n",
      "14:44:22.263 [INFO] Epoch: 90, Loss: 0.1718844771\n",
      "14:44:22.472 [INFO] Epoch: 100, Loss: 0.1631981432\n",
      "14:44:22.687 [INFO] Epoch: 110, Loss: 0.2223905176\n",
      "14:44:22.891 [INFO] Epoch: 120, Loss: 0.1572889239\n",
      "14:44:23.102 [INFO] Epoch: 130, Loss: 0.1992918849\n",
      "14:44:23.322 [INFO] Epoch: 140, Loss: 0.1646858156\n",
      "14:44:23.540 [INFO] Epoch: 150, Loss: 0.1696760803\n",
      "14:44:23.756 [INFO] Epoch: 160, Loss: 0.1501854360\n",
      "14:44:23.970 [INFO] Epoch: 170, Loss: 0.1623058617\n",
      "14:44:24.170 [INFO] Epoch: 180, Loss: 0.1598191410\n",
      "14:44:24.383 [INFO] Epoch: 190, Loss: 0.1551375389\n",
      "14:44:24.587 [INFO] Epoch: 200, Loss: 0.1525179446\n",
      "14:44:24.791 [INFO] Epoch: 210, Loss: 0.1448040307\n",
      "14:44:24.991 [INFO] Epoch: 220, Loss: 0.1501300335\n",
      "14:44:25.196 [INFO] Epoch: 230, Loss: 0.1571381390\n",
      "14:44:25.405 [INFO] Epoch: 240, Loss: 0.1557469964\n",
      "14:44:25.622 [INFO] Epoch: 250, Loss: 0.1533408612\n",
      "14:44:25.750 [INFO] Epoch: 256, Loss: 0.1581158936\n",
      "14:44:25.751 [INFO] Pruning weights (5 / 62)\n",
      "14:44:25.837 [INFO] Shed 0.19420570135116577 weight\n",
      "14:44:25.973 [INFO] Constructed symbolic model\n",
      "14:44:26.961 [INFO] Constructed loss equation\n",
      "14:44:28.421 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:44:32.520 [INFO] Epoch: 1, Loss: 0.4855793118\n",
      "14:44:32.708 [INFO] Epoch: 10, Loss: 0.1966865957\n",
      "14:44:32.979 [INFO] Epoch: 20, Loss: 0.1564878672\n",
      "14:44:33.242 [INFO] Epoch: 30, Loss: 0.1616712809\n",
      "14:44:33.486 [INFO] Epoch: 40, Loss: 0.1515611112\n",
      "14:44:33.713 [INFO] Epoch: 50, Loss: 0.1608490199\n",
      "14:44:34.130 [INFO] Epoch: 60, Loss: 0.1444868743\n",
      "14:44:34.257 [INFO] Epoch: 70, Loss: 0.1552223563\n",
      "14:44:34.489 [INFO] Epoch: 80, Loss: 0.1638875008\n",
      "14:44:34.711 [INFO] Epoch: 90, Loss: 0.1572604179\n",
      "14:44:34.989 [INFO] Epoch: 100, Loss: 0.1606138945\n",
      "14:44:35.212 [INFO] Epoch: 110, Loss: 0.1652049869\n",
      "14:44:35.431 [INFO] Epoch: 120, Loss: 0.1502096653\n",
      "14:44:35.700 [INFO] Epoch: 130, Loss: 0.1501096487\n",
      "14:44:35.945 [INFO] Epoch: 140, Loss: 0.1473284364\n",
      "14:44:36.171 [INFO] Epoch: 150, Loss: 0.1500765085\n",
      "14:44:36.411 [INFO] Epoch: 160, Loss: 0.1415606439\n",
      "14:44:36.655 [INFO] Epoch: 170, Loss: 0.1461842060\n",
      "14:44:36.906 [INFO] Epoch: 180, Loss: 0.1387596279\n",
      "14:44:37.120 [INFO] Epoch: 190, Loss: 0.1624705344\n",
      "14:44:37.344 [INFO] Epoch: 200, Loss: 0.1447085589\n",
      "14:44:37.551 [INFO] Epoch: 210, Loss: 0.1498341560\n",
      "14:44:37.769 [INFO] Epoch: 220, Loss: 0.1381076574\n",
      "14:44:37.985 [INFO] Epoch: 230, Loss: 0.1418083757\n",
      "14:44:38.220 [INFO] Epoch: 240, Loss: 0.1376928985\n",
      "14:44:38.473 [INFO] Epoch: 250, Loss: 0.1473468393\n",
      "14:44:38.622 [INFO] Epoch: 256, Loss: 0.1383052766\n",
      "14:44:38.623 [INFO] Pruning weights (6 / 62)\n",
      "14:44:38.665 [INFO] Shed 0.0007578750373795629 weight\n",
      "14:44:38.757 [INFO] Constructed symbolic model\n",
      "14:44:39.762 [INFO] Constructed loss equation\n",
      "14:44:41.314 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:44:45.282 [INFO] Epoch: 1, Loss: 0.8349428177\n",
      "14:44:45.497 [INFO] Epoch: 10, Loss: 0.1557914615\n",
      "14:44:45.747 [INFO] Epoch: 20, Loss: 0.1509802192\n",
      "14:44:46.300 [INFO] Epoch: 30, Loss: 0.1657254100\n",
      "14:44:46.258 [INFO] Epoch: 40, Loss: 0.1622353196\n",
      "14:44:46.557 [INFO] Epoch: 50, Loss: 0.1855291724\n",
      "14:44:46.815 [INFO] Epoch: 60, Loss: 0.1646362841\n",
      "14:44:47.550 [INFO] Epoch: 70, Loss: 0.1597425342\n",
      "14:44:47.289 [INFO] Epoch: 80, Loss: 0.1571897566\n",
      "14:44:47.523 [INFO] Epoch: 90, Loss: 0.1517875940\n",
      "14:44:47.789 [INFO] Epoch: 100, Loss: 0.1483831406\n",
      "14:44:48.900 [INFO] Epoch: 110, Loss: 0.1447887570\n",
      "14:44:48.260 [INFO] Epoch: 120, Loss: 0.1423481107\n",
      "14:44:48.594 [INFO] Epoch: 130, Loss: 0.1426521391\n",
      "14:44:48.816 [INFO] Epoch: 140, Loss: 0.1505951881\n",
      "14:44:49.370 [INFO] Epoch: 150, Loss: 0.1391954422\n",
      "14:44:49.407 [INFO] Epoch: 160, Loss: 0.1529356837\n",
      "14:44:49.774 [INFO] Epoch: 170, Loss: 0.1381278932\n",
      "14:44:49.980 [INFO] Epoch: 180, Loss: 0.1477754116\n",
      "14:44:50.194 [INFO] Epoch: 190, Loss: 0.1366587877\n",
      "14:44:50.408 [INFO] Epoch: 200, Loss: 0.1401870847\n",
      "14:44:50.635 [INFO] Epoch: 210, Loss: 0.1430786699\n",
      "14:44:50.868 [INFO] Epoch: 220, Loss: 0.1384138465\n",
      "14:44:51.940 [INFO] Epoch: 230, Loss: 0.1447235346\n",
      "14:44:51.318 [INFO] Epoch: 240, Loss: 0.1366381049\n",
      "14:44:51.531 [INFO] Epoch: 250, Loss: 0.1404684633\n",
      "14:44:51.655 [INFO] Epoch: 256, Loss: 0.1314057112\n",
      "14:44:51.656 [INFO] Pruning weights (7 / 62)\n",
      "14:44:51.706 [INFO] Shed 0.0019530192948877811 weight\n",
      "14:44:51.814 [INFO] Constructed symbolic model\n",
      "14:44:52.525 [INFO] Constructed loss equation\n",
      "14:44:53.930 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:44:57.213 [INFO] Epoch: 1, Loss: 0.5994721651\n",
      "14:44:57.397 [INFO] Epoch: 10, Loss: 0.2074624896\n",
      "14:44:57.600 [INFO] Epoch: 20, Loss: 0.1485782564\n",
      "14:44:57.845 [INFO] Epoch: 30, Loss: 0.1481989473\n",
      "14:44:58.560 [INFO] Epoch: 40, Loss: 0.1484731883\n",
      "14:44:58.266 [INFO] Epoch: 50, Loss: 0.1564649045\n",
      "14:44:58.485 [INFO] Epoch: 60, Loss: 0.1342132390\n",
      "14:44:58.679 [INFO] Epoch: 70, Loss: 0.1547684222\n",
      "14:44:58.878 [INFO] Epoch: 80, Loss: 0.1443768442\n",
      "14:44:59.780 [INFO] Epoch: 90, Loss: 0.2068931758\n",
      "14:44:59.274 [INFO] Epoch: 100, Loss: 0.1460857093\n",
      "14:44:59.470 [INFO] Epoch: 110, Loss: 0.1412384957\n",
      "14:44:59.667 [INFO] Epoch: 120, Loss: 0.1422211230\n",
      "14:44:59.866 [INFO] Epoch: 130, Loss: 0.1613880992\n",
      "14:45:00.660 [INFO] Epoch: 140, Loss: 0.1286032051\n",
      "14:45:00.257 [INFO] Epoch: 150, Loss: 0.1371508241\n",
      "14:45:00.453 [INFO] Epoch: 160, Loss: 0.1443443596\n",
      "14:45:00.658 [INFO] Epoch: 170, Loss: 0.1514312625\n",
      "14:45:00.872 [INFO] Epoch: 180, Loss: 0.1419066787\n",
      "14:45:01.690 [INFO] Epoch: 190, Loss: 0.1417504996\n",
      "14:45:01.504 [INFO] Epoch: 200, Loss: 0.1379317790\n",
      "14:45:01.844 [INFO] Epoch: 210, Loss: 0.1435986310\n",
      "14:45:02.154 [INFO] Epoch: 220, Loss: 0.1357514858\n",
      "14:45:02.410 [INFO] Epoch: 230, Loss: 0.1370036900\n",
      "14:45:02.639 [INFO] Epoch: 240, Loss: 0.1253129840\n",
      "14:45:02.864 [INFO] Epoch: 250, Loss: 0.1280801147\n",
      "14:45:03.120 [INFO] Epoch: 256, Loss: 0.1237142459\n",
      "14:45:03.130 [INFO] Pruning weights (8 / 62)\n",
      "14:45:03.680 [INFO] Shed 0.1555592119693756 weight\n",
      "14:45:03.206 [INFO] Constructed symbolic model\n",
      "14:45:04.133 [INFO] Constructed loss equation\n",
      "14:45:05.541 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:45:08.824 [INFO] Epoch: 1, Loss: 0.5833895206\n",
      "14:45:09.320 [INFO] Epoch: 10, Loss: 0.1851776242\n",
      "14:45:09.263 [INFO] Epoch: 20, Loss: 0.1381277889\n",
      "14:45:09.485 [INFO] Epoch: 30, Loss: 0.1391591430\n",
      "14:45:09.716 [INFO] Epoch: 40, Loss: 0.1538812816\n",
      "14:45:09.951 [INFO] Epoch: 50, Loss: 0.1470709443\n",
      "14:45:10.169 [INFO] Epoch: 60, Loss: 0.1383765340\n",
      "14:45:10.396 [INFO] Epoch: 70, Loss: 0.1461794823\n",
      "14:45:10.615 [INFO] Epoch: 80, Loss: 0.1403423548\n",
      "14:45:10.829 [INFO] Epoch: 90, Loss: 0.1383902282\n",
      "14:45:11.620 [INFO] Epoch: 100, Loss: 0.1452485770\n",
      "14:45:11.315 [INFO] Epoch: 110, Loss: 0.1278019398\n",
      "14:45:11.537 [INFO] Epoch: 120, Loss: 0.1413447857\n",
      "14:45:11.740 [INFO] Epoch: 130, Loss: 0.1389617771\n",
      "14:45:11.971 [INFO] Epoch: 140, Loss: 0.1412200034\n",
      "14:45:12.177 [INFO] Epoch: 150, Loss: 0.1425532401\n",
      "14:45:12.389 [INFO] Epoch: 160, Loss: 0.1321784258\n",
      "14:45:12.582 [INFO] Epoch: 170, Loss: 0.1279974431\n",
      "14:45:12.775 [INFO] Epoch: 180, Loss: 0.1332051754\n",
      "14:45:12.969 [INFO] Epoch: 190, Loss: 0.1401125640\n",
      "14:45:13.169 [INFO] Epoch: 200, Loss: 0.1219600514\n",
      "14:45:13.368 [INFO] Epoch: 210, Loss: 0.1345681399\n",
      "14:45:13.566 [INFO] Epoch: 220, Loss: 0.1247212365\n",
      "14:45:13.763 [INFO] Epoch: 230, Loss: 0.1247208863\n",
      "14:45:13.997 [INFO] Epoch: 240, Loss: 0.1291709244\n",
      "14:45:14.226 [INFO] Epoch: 250, Loss: 0.1267046034\n",
      "14:45:14.352 [INFO] Epoch: 256, Loss: 0.1354822665\n",
      "14:45:14.353 [INFO] Pruning weights (9 / 62)\n",
      "14:45:14.407 [INFO] Shed 0.22336292266845703 weight\n",
      "14:45:14.492 [INFO] Constructed symbolic model\n",
      "14:45:15.486 [INFO] Constructed loss equation\n",
      "14:45:16.885 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:45:20.183 [INFO] Epoch: 1, Loss: 0.5716061592\n",
      "14:45:20.368 [INFO] Epoch: 10, Loss: 0.1743393540\n",
      "14:45:20.594 [INFO] Epoch: 20, Loss: 0.1499210298\n",
      "14:45:20.805 [INFO] Epoch: 30, Loss: 0.1424253732\n",
      "14:45:21.150 [INFO] Epoch: 40, Loss: 0.1788459420\n",
      "14:45:21.229 [INFO] Epoch: 50, Loss: 0.1371415257\n",
      "14:45:21.434 [INFO] Epoch: 60, Loss: 0.1439765692\n",
      "14:45:21.628 [INFO] Epoch: 70, Loss: 0.1212628782\n",
      "14:45:21.827 [INFO] Epoch: 80, Loss: 0.1363698691\n",
      "14:45:22.260 [INFO] Epoch: 90, Loss: 0.1481554508\n",
      "14:45:22.232 [INFO] Epoch: 100, Loss: 0.1258239597\n",
      "14:45:22.428 [INFO] Epoch: 110, Loss: 0.1276772767\n",
      "14:45:22.626 [INFO] Epoch: 120, Loss: 0.1365536749\n",
      "14:45:22.821 [INFO] Epoch: 130, Loss: 0.1312592328\n",
      "14:45:23.240 [INFO] Epoch: 140, Loss: 0.1394067705\n",
      "14:45:23.214 [INFO] Epoch: 150, Loss: 0.1326115131\n",
      "14:45:23.405 [INFO] Epoch: 160, Loss: 0.1327112019\n",
      "14:45:23.595 [INFO] Epoch: 170, Loss: 0.1359995008\n",
      "14:45:23.787 [INFO] Epoch: 180, Loss: 0.1317786723\n",
      "14:45:23.979 [INFO] Epoch: 190, Loss: 0.1266829073\n",
      "14:45:24.169 [INFO] Epoch: 200, Loss: 0.1314533502\n",
      "14:45:24.361 [INFO] Epoch: 210, Loss: 0.1299455017\n",
      "14:45:24.555 [INFO] Epoch: 220, Loss: 0.1338898391\n",
      "14:45:24.746 [INFO] Epoch: 230, Loss: 0.1298319548\n",
      "14:45:24.944 [INFO] Epoch: 240, Loss: 0.1261730790\n",
      "14:45:25.137 [INFO] Epoch: 250, Loss: 0.1243935525\n",
      "14:45:25.253 [INFO] Epoch: 256, Loss: 0.1193112880\n",
      "14:45:25.254 [INFO] Pruning weights (10 / 62)\n",
      "14:45:25.301 [INFO] Shed 0.29063543677330017 weight\n",
      "14:45:25.379 [INFO] Constructed symbolic model\n",
      "14:45:26.800 [INFO] Constructed loss equation\n",
      "14:45:27.201 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:45:30.144 [INFO] Epoch: 1, Loss: 0.4976274967\n",
      "14:45:30.329 [INFO] Epoch: 10, Loss: 0.1249340922\n",
      "14:45:30.530 [INFO] Epoch: 20, Loss: 0.1852477193\n",
      "14:45:30.732 [INFO] Epoch: 30, Loss: 0.1314319223\n",
      "14:45:30.938 [INFO] Epoch: 40, Loss: 0.1398752630\n",
      "14:45:31.133 [INFO] Epoch: 50, Loss: 0.1236581206\n",
      "14:45:31.390 [INFO] Epoch: 60, Loss: 0.1279719174\n",
      "14:45:31.634 [INFO] Epoch: 70, Loss: 0.1341925412\n",
      "14:45:31.861 [INFO] Epoch: 80, Loss: 0.1692954004\n",
      "14:45:32.740 [INFO] Epoch: 90, Loss: 0.1315524727\n",
      "14:45:32.303 [INFO] Epoch: 100, Loss: 0.1486918032\n",
      "14:45:32.539 [INFO] Epoch: 110, Loss: 0.1417851597\n",
      "14:45:32.757 [INFO] Epoch: 120, Loss: 0.1276326180\n",
      "14:45:32.982 [INFO] Epoch: 130, Loss: 0.1317743957\n",
      "14:45:33.198 [INFO] Epoch: 140, Loss: 0.1442252100\n",
      "14:45:33.399 [INFO] Epoch: 150, Loss: 0.1245044246\n",
      "14:45:33.672 [INFO] Epoch: 160, Loss: 0.1347494721\n",
      "14:45:33.868 [INFO] Epoch: 170, Loss: 0.1923151612\n",
      "14:45:34.610 [INFO] Epoch: 180, Loss: 0.1391818225\n",
      "14:45:34.263 [INFO] Epoch: 190, Loss: 0.1288297176\n",
      "14:45:34.467 [INFO] Epoch: 200, Loss: 0.1360033751\n",
      "14:45:34.676 [INFO] Epoch: 210, Loss: 0.1204825491\n",
      "14:45:34.888 [INFO] Epoch: 220, Loss: 0.1206077486\n",
      "14:45:35.980 [INFO] Epoch: 230, Loss: 0.1329086721\n",
      "14:45:35.301 [INFO] Epoch: 240, Loss: 0.1300390363\n",
      "14:45:35.501 [INFO] Epoch: 250, Loss: 0.1249131709\n",
      "14:45:35.622 [INFO] Epoch: 256, Loss: 0.1205851659\n",
      "14:45:35.622 [INFO] Pruning weights (11 / 62)\n",
      "14:45:35.659 [INFO] Shed 0.0013339970028027892 weight\n",
      "14:45:35.749 [INFO] Constructed symbolic model\n",
      "14:45:36.437 [INFO] Constructed loss equation\n",
      "14:45:37.617 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:45:40.625 [INFO] Epoch: 1, Loss: 0.3429844081\n",
      "14:45:40.797 [INFO] Epoch: 10, Loss: 0.1416715384\n",
      "14:45:40.995 [INFO] Epoch: 20, Loss: 0.1596254855\n",
      "14:45:41.198 [INFO] Epoch: 30, Loss: 0.1345918179\n",
      "14:45:41.397 [INFO] Epoch: 40, Loss: 0.1331749856\n",
      "14:45:41.597 [INFO] Epoch: 50, Loss: 0.1526986063\n",
      "14:45:41.835 [INFO] Epoch: 60, Loss: 0.1297020614\n",
      "14:45:42.720 [INFO] Epoch: 70, Loss: 0.1379080415\n",
      "14:45:42.284 [INFO] Epoch: 80, Loss: 0.1454365551\n",
      "14:45:42.494 [INFO] Epoch: 90, Loss: 0.1293211579\n",
      "14:45:42.768 [INFO] Epoch: 100, Loss: 0.1322405636\n",
      "14:45:43.114 [INFO] Epoch: 110, Loss: 0.1281086206\n",
      "14:45:43.490 [INFO] Epoch: 120, Loss: 0.1255230308\n",
      "14:45:43.818 [INFO] Epoch: 130, Loss: 0.1221871078\n",
      "14:45:44.114 [INFO] Epoch: 140, Loss: 0.1215930507\n",
      "14:45:44.507 [INFO] Epoch: 150, Loss: 0.1396015286\n",
      "14:45:44.852 [INFO] Epoch: 160, Loss: 0.1424225569\n",
      "14:45:45.225 [INFO] Epoch: 170, Loss: 0.1338292062\n",
      "14:45:45.644 [INFO] Epoch: 180, Loss: 0.1335223019\n",
      "14:45:45.925 [INFO] Epoch: 190, Loss: 0.1321514845\n",
      "14:45:46.224 [INFO] Epoch: 200, Loss: 0.1258386075\n",
      "14:45:46.533 [INFO] Epoch: 210, Loss: 0.1214198247\n",
      "14:45:46.901 [INFO] Epoch: 220, Loss: 0.1223334372\n",
      "14:45:47.268 [INFO] Epoch: 230, Loss: 0.1367950737\n",
      "14:45:47.572 [INFO] Epoch: 240, Loss: 0.1179984063\n",
      "14:45:47.917 [INFO] Epoch: 250, Loss: 0.1207125485\n",
      "14:45:48.138 [INFO] Epoch: 256, Loss: 0.1217805594\n",
      "14:45:48.139 [INFO] Pruning weights (12 / 62)\n",
      "14:45:48.204 [INFO] Shed 0.006240928545594215 weight\n",
      "14:45:48.306 [INFO] Constructed symbolic model\n",
      "14:45:49.418 [INFO] Constructed loss equation\n",
      "14:45:51.700 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:45:54.213 [INFO] Epoch: 1, Loss: 1.0215185881\n",
      "14:45:54.440 [INFO] Epoch: 10, Loss: 0.1355481595\n",
      "14:45:54.744 [INFO] Epoch: 20, Loss: 0.1425063461\n",
      "14:45:54.990 [INFO] Epoch: 30, Loss: 0.1526669860\n",
      "14:45:55.213 [INFO] Epoch: 40, Loss: 0.1591677517\n",
      "14:45:55.452 [INFO] Epoch: 50, Loss: 0.1466051638\n",
      "14:45:55.676 [INFO] Epoch: 60, Loss: 0.1555198431\n",
      "14:45:55.910 [INFO] Epoch: 70, Loss: 0.1284654289\n",
      "14:45:56.140 [INFO] Epoch: 80, Loss: 0.1399896592\n",
      "14:45:56.378 [INFO] Epoch: 90, Loss: 0.1616844237\n",
      "14:45:56.595 [INFO] Epoch: 100, Loss: 0.1493279338\n",
      "14:45:56.815 [INFO] Epoch: 110, Loss: 0.1525786221\n",
      "14:45:57.360 [INFO] Epoch: 120, Loss: 0.1258871108\n",
      "14:45:57.300 [INFO] Epoch: 130, Loss: 0.1348519325\n",
      "14:45:57.522 [INFO] Epoch: 140, Loss: 0.1219231114\n",
      "14:45:57.750 [INFO] Epoch: 150, Loss: 0.1395758539\n",
      "14:45:57.988 [INFO] Epoch: 160, Loss: 0.1374695897\n",
      "14:45:58.248 [INFO] Epoch: 170, Loss: 0.1340689510\n",
      "14:45:58.458 [INFO] Epoch: 180, Loss: 0.1274511814\n",
      "14:45:58.659 [INFO] Epoch: 190, Loss: 0.1272715628\n",
      "14:45:58.869 [INFO] Epoch: 200, Loss: 0.1263642460\n",
      "14:45:59.101 [INFO] Epoch: 210, Loss: 0.1306511760\n",
      "14:45:59.390 [INFO] Epoch: 220, Loss: 0.1255540848\n",
      "14:45:59.624 [INFO] Epoch: 230, Loss: 0.1292664111\n",
      "14:45:59.854 [INFO] Epoch: 240, Loss: 0.1206645966\n",
      "14:46:00.750 [INFO] Epoch: 250, Loss: 0.1218460351\n",
      "14:46:00.215 [INFO] Epoch: 256, Loss: 0.1229756027\n",
      "14:46:00.215 [INFO] Pruning weights (13 / 62)\n",
      "14:46:00.273 [INFO] Shed 0.01000418234616518 weight\n",
      "14:46:00.370 [INFO] Constructed symbolic model\n",
      "14:46:01.294 [INFO] Constructed loss equation\n",
      "14:46:02.598 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:46:05.806 [INFO] Epoch: 1, Loss: 0.3550410867\n",
      "14:46:06.137 [INFO] Epoch: 10, Loss: 0.1511436403\n",
      "14:46:06.574 [INFO] Epoch: 20, Loss: 0.1368651986\n",
      "14:46:06.958 [INFO] Epoch: 30, Loss: 0.1357628852\n",
      "14:46:07.376 [INFO] Epoch: 40, Loss: 0.1504574120\n",
      "14:46:07.704 [INFO] Epoch: 50, Loss: 0.1185610890\n",
      "14:46:07.986 [INFO] Epoch: 60, Loss: 0.1331667304\n",
      "14:46:08.322 [INFO] Epoch: 70, Loss: 0.1414131224\n",
      "14:46:08.629 [INFO] Epoch: 80, Loss: 0.1328833997\n",
      "14:46:08.908 [INFO] Epoch: 90, Loss: 0.1316658556\n",
      "14:46:09.189 [INFO] Epoch: 100, Loss: 0.1358565241\n",
      "14:46:09.436 [INFO] Epoch: 110, Loss: 0.1255560368\n",
      "14:46:09.662 [INFO] Epoch: 120, Loss: 0.1610394418\n",
      "14:46:09.889 [INFO] Epoch: 130, Loss: 0.1327382624\n",
      "14:46:10.104 [INFO] Epoch: 140, Loss: 0.1524117887\n",
      "14:46:10.322 [INFO] Epoch: 150, Loss: 0.1253903508\n",
      "14:46:10.564 [INFO] Epoch: 160, Loss: 0.1257702559\n",
      "14:46:10.787 [INFO] Epoch: 170, Loss: 0.1222327501\n",
      "14:46:11.470 [INFO] Epoch: 180, Loss: 0.1244268566\n",
      "14:46:11.399 [INFO] Epoch: 190, Loss: 0.1323604733\n",
      "14:46:11.750 [INFO] Epoch: 200, Loss: 0.1169212461\n",
      "14:46:11.1000 [INFO] Epoch: 210, Loss: 0.1283824742\n",
      "14:46:12.250 [INFO] Epoch: 220, Loss: 0.1210888177\n",
      "14:46:12.467 [INFO] Epoch: 230, Loss: 0.1215655357\n",
      "14:46:12.722 [INFO] Epoch: 240, Loss: 0.1278498471\n",
      "14:46:12.934 [INFO] Epoch: 250, Loss: 0.1180908978\n",
      "14:46:13.610 [INFO] Epoch: 256, Loss: 0.1152198538\n",
      "14:46:13.620 [INFO] Pruning weights (14 / 62)\n",
      "14:46:13.112 [INFO] Shed 0.10362260788679123 weight\n",
      "14:46:13.178 [INFO] Constructed symbolic model\n",
      "14:46:14.630 [INFO] Constructed loss equation\n",
      "14:46:15.539 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:46:19.244 [INFO] Epoch: 1, Loss: 0.9486366510\n",
      "14:46:19.534 [INFO] Epoch: 10, Loss: 0.1451328397\n",
      "14:46:19.884 [INFO] Epoch: 20, Loss: 0.1484368593\n",
      "14:46:20.157 [INFO] Epoch: 30, Loss: 0.1758190393\n",
      "14:46:20.468 [INFO] Epoch: 40, Loss: 0.1275892258\n",
      "14:46:20.733 [INFO] Epoch: 50, Loss: 0.1295357347\n",
      "14:46:20.990 [INFO] Epoch: 60, Loss: 0.1247084811\n",
      "14:46:21.238 [INFO] Epoch: 70, Loss: 0.1377848685\n",
      "14:46:21.492 [INFO] Epoch: 80, Loss: 0.1572421789\n",
      "14:46:21.741 [INFO] Epoch: 90, Loss: 0.1309068799\n",
      "14:46:21.996 [INFO] Epoch: 100, Loss: 0.1506414711\n",
      "14:46:22.230 [INFO] Epoch: 110, Loss: 0.1625667214\n",
      "14:46:22.468 [INFO] Epoch: 120, Loss: 0.1313983500\n",
      "14:46:22.720 [INFO] Epoch: 130, Loss: 0.1269950718\n",
      "14:46:23.900 [INFO] Epoch: 140, Loss: 0.1181909814\n",
      "14:46:23.336 [INFO] Epoch: 150, Loss: 0.1246968955\n",
      "14:46:23.680 [INFO] Epoch: 160, Loss: 0.1406553537\n",
      "14:46:24.510 [INFO] Epoch: 170, Loss: 0.1269934475\n",
      "14:46:24.392 [INFO] Epoch: 180, Loss: 0.1299225241\n",
      "14:46:24.736 [INFO] Epoch: 190, Loss: 0.1273784935\n",
      "14:46:25.770 [INFO] Epoch: 200, Loss: 0.1279132962\n",
      "14:46:25.422 [INFO] Epoch: 210, Loss: 0.1220437437\n",
      "14:46:25.787 [INFO] Epoch: 220, Loss: 0.1284251660\n",
      "14:46:26.970 [INFO] Epoch: 230, Loss: 0.1274132431\n",
      "14:46:26.391 [INFO] Epoch: 240, Loss: 0.1242484227\n",
      "14:46:26.685 [INFO] Epoch: 250, Loss: 0.1224181950\n",
      "14:46:26.851 [INFO] Epoch: 256, Loss: 0.1200079098\n",
      "14:46:26.852 [INFO] Pruning weights (15 / 62)\n",
      "14:46:26.924 [INFO] Shed 0.11843949556350708 weight\n",
      "14:46:26.996 [INFO] Constructed symbolic model\n",
      "14:46:27.666 [INFO] Constructed loss equation\n",
      "14:46:28.936 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:46:32.662 [INFO] Epoch: 1, Loss: 0.7041162252\n",
      "14:46:32.974 [INFO] Epoch: 10, Loss: 0.1362166852\n",
      "14:46:33.311 [INFO] Epoch: 20, Loss: 0.1267105341\n",
      "14:46:33.643 [INFO] Epoch: 30, Loss: 0.1228818819\n",
      "14:46:33.980 [INFO] Epoch: 40, Loss: 0.1272603720\n",
      "14:46:34.312 [INFO] Epoch: 50, Loss: 0.1447773278\n",
      "14:46:34.656 [INFO] Epoch: 60, Loss: 0.1480669081\n",
      "14:46:35.900 [INFO] Epoch: 70, Loss: 0.1330480576\n",
      "14:46:35.273 [INFO] Epoch: 80, Loss: 0.1230554804\n",
      "14:46:35.523 [INFO] Epoch: 90, Loss: 0.1246071011\n",
      "14:46:35.772 [INFO] Epoch: 100, Loss: 0.1224261895\n",
      "14:46:36.260 [INFO] Epoch: 110, Loss: 0.1306269467\n",
      "14:46:36.305 [INFO] Epoch: 120, Loss: 0.1290054619\n",
      "14:46:36.577 [INFO] Epoch: 130, Loss: 0.1244555116\n",
      "14:46:36.826 [INFO] Epoch: 140, Loss: 0.1243321821\n",
      "14:46:37.740 [INFO] Epoch: 150, Loss: 0.1335866451\n",
      "14:46:37.328 [INFO] Epoch: 160, Loss: 0.1149521694\n",
      "14:46:37.570 [INFO] Epoch: 170, Loss: 0.1200073510\n",
      "14:46:37.818 [INFO] Epoch: 180, Loss: 0.1209611744\n",
      "14:46:38.590 [INFO] Epoch: 190, Loss: 0.1202852204\n",
      "14:46:38.297 [INFO] Epoch: 200, Loss: 0.1256840527\n",
      "14:46:38.530 [INFO] Epoch: 210, Loss: 0.1151582599\n",
      "14:46:38.789 [INFO] Epoch: 220, Loss: 0.1198709607\n",
      "14:46:39.730 [INFO] Epoch: 230, Loss: 0.1272666454\n",
      "14:46:39.337 [INFO] Epoch: 240, Loss: 0.1168166026\n",
      "14:46:39.587 [INFO] Epoch: 250, Loss: 0.1179794967\n",
      "14:46:39.734 [INFO] Epoch: 256, Loss: 0.1222001240\n",
      "14:46:39.735 [INFO] Pruning weights (16 / 62)\n",
      "14:46:39.778 [INFO] Shed 0.0004926157416775823 weight\n",
      "14:46:39.838 [INFO] Constructed symbolic model\n",
      "14:46:40.479 [INFO] Constructed loss equation\n",
      "14:46:41.723 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:46:44.760 [INFO] Epoch: 1, Loss: 0.6459711790\n",
      "14:46:45.260 [INFO] Epoch: 10, Loss: 0.1352155209\n",
      "14:46:45.303 [INFO] Epoch: 20, Loss: 0.1281830817\n",
      "14:46:45.603 [INFO] Epoch: 30, Loss: 0.1252772808\n",
      "14:46:45.902 [INFO] Epoch: 40, Loss: 0.1332140863\n",
      "14:46:46.204 [INFO] Epoch: 50, Loss: 0.1305394769\n",
      "14:46:46.457 [INFO] Epoch: 60, Loss: 0.1238114983\n",
      "14:46:46.726 [INFO] Epoch: 70, Loss: 0.1249677166\n",
      "14:46:46.968 [INFO] Epoch: 80, Loss: 0.1326532066\n",
      "14:46:47.216 [INFO] Epoch: 90, Loss: 0.1313356310\n",
      "14:46:47.465 [INFO] Epoch: 100, Loss: 0.1237729415\n",
      "14:46:47.725 [INFO] Epoch: 110, Loss: 0.1256527603\n",
      "14:46:47.974 [INFO] Epoch: 120, Loss: 0.1254562587\n",
      "14:46:48.228 [INFO] Epoch: 130, Loss: 0.1234037727\n",
      "14:46:48.482 [INFO] Epoch: 140, Loss: 0.1343582422\n",
      "14:46:48.738 [INFO] Epoch: 150, Loss: 0.1306334734\n",
      "14:46:48.994 [INFO] Epoch: 160, Loss: 0.1112001240\n",
      "14:46:49.285 [INFO] Epoch: 170, Loss: 0.1240659654\n",
      "14:46:49.579 [INFO] Epoch: 180, Loss: 0.1205684692\n",
      "14:46:49.864 [INFO] Epoch: 190, Loss: 0.1163726449\n",
      "14:46:50.129 [INFO] Epoch: 200, Loss: 0.1274350733\n",
      "14:46:50.398 [INFO] Epoch: 210, Loss: 0.1185943708\n",
      "14:46:50.648 [INFO] Epoch: 220, Loss: 0.1137128472\n",
      "14:46:50.958 [INFO] Epoch: 230, Loss: 0.1266048551\n",
      "14:46:51.223 [INFO] Epoch: 240, Loss: 0.1200341284\n",
      "14:46:51.510 [INFO] Epoch: 250, Loss: 0.1188332587\n",
      "14:46:51.717 [INFO] Epoch: 256, Loss: 0.1201565862\n",
      "14:46:51.718 [INFO] Pruning weights (17 / 62)\n",
      "14:46:51.774 [INFO] Shed 0.0026770527474582195 weight\n",
      "14:46:51.873 [INFO] Constructed symbolic model\n",
      "14:46:52.666 [INFO] Constructed loss equation\n",
      "14:46:54.340 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:46:57.212 [INFO] Epoch: 1, Loss: 0.4839382768\n",
      "14:46:57.440 [INFO] Epoch: 10, Loss: 0.1327991486\n",
      "14:46:57.744 [INFO] Epoch: 20, Loss: 0.1180475652\n",
      "14:46:57.996 [INFO] Epoch: 30, Loss: 0.1297763586\n",
      "14:46:58.244 [INFO] Epoch: 40, Loss: 0.1311694384\n",
      "14:46:58.486 [INFO] Epoch: 50, Loss: 0.1166419685\n",
      "14:46:58.779 [INFO] Epoch: 60, Loss: 0.1205562204\n",
      "14:46:59.440 [INFO] Epoch: 70, Loss: 0.1189584732\n",
      "14:46:59.334 [INFO] Epoch: 80, Loss: 0.1309807301\n",
      "14:46:59.612 [INFO] Epoch: 90, Loss: 0.1206076294\n",
      "14:46:59.887 [INFO] Epoch: 100, Loss: 0.1162649244\n",
      "14:47:00.149 [INFO] Epoch: 110, Loss: 0.1283819675\n",
      "14:47:00.430 [INFO] Epoch: 120, Loss: 0.1303471029\n",
      "14:47:00.708 [INFO] Epoch: 130, Loss: 0.1255115718\n",
      "14:47:00.955 [INFO] Epoch: 140, Loss: 0.1225200742\n",
      "14:47:01.206 [INFO] Epoch: 150, Loss: 0.1172704101\n",
      "14:47:01.491 [INFO] Epoch: 160, Loss: 0.1268497705\n",
      "14:47:01.830 [INFO] Epoch: 170, Loss: 0.1221460104\n",
      "14:47:02.910 [INFO] Epoch: 180, Loss: 0.1301878542\n",
      "14:47:02.369 [INFO] Epoch: 190, Loss: 0.1199418604\n",
      "14:47:02.696 [INFO] Epoch: 200, Loss: 0.1194529980\n",
      "14:47:02.938 [INFO] Epoch: 210, Loss: 0.1118737459\n",
      "14:47:03.179 [INFO] Epoch: 220, Loss: 0.1173199117\n",
      "14:47:03.458 [INFO] Epoch: 230, Loss: 0.1191106737\n",
      "14:47:03.722 [INFO] Epoch: 240, Loss: 0.1161740422\n",
      "14:47:03.967 [INFO] Epoch: 250, Loss: 0.1144056320\n",
      "14:47:04.118 [INFO] Epoch: 256, Loss: 0.1148967817\n",
      "14:47:04.119 [INFO] Pruning weights (18 / 62)\n",
      "14:47:04.167 [INFO] Shed 0.024411506950855255 weight\n",
      "14:47:04.238 [INFO] Constructed symbolic model\n",
      "14:47:04.909 [INFO] Constructed loss equation\n",
      "14:47:06.315 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:47:09.532 [INFO] Epoch: 1, Loss: 0.2112386525\n",
      "14:47:09.783 [INFO] Epoch: 10, Loss: 0.1257764399\n",
      "14:47:10.770 [INFO] Epoch: 20, Loss: 0.1256964356\n",
      "14:47:10.338 [INFO] Epoch: 30, Loss: 0.1144262925\n",
      "14:47:10.610 [INFO] Epoch: 40, Loss: 0.1216034293\n",
      "14:47:10.881 [INFO] Epoch: 50, Loss: 0.1254641414\n",
      "14:47:11.122 [INFO] Epoch: 60, Loss: 0.1444024146\n",
      "14:47:11.368 [INFO] Epoch: 70, Loss: 0.1197251901\n",
      "14:47:11.618 [INFO] Epoch: 80, Loss: 0.1153270304\n",
      "14:47:11.832 [INFO] Epoch: 90, Loss: 0.1135739684\n",
      "14:47:12.460 [INFO] Epoch: 100, Loss: 0.1210256517\n",
      "14:47:12.267 [INFO] Epoch: 110, Loss: 0.1335824728\n",
      "14:47:12.499 [INFO] Epoch: 120, Loss: 0.1138255373\n",
      "14:47:12.727 [INFO] Epoch: 130, Loss: 0.1340241134\n",
      "14:47:12.941 [INFO] Epoch: 140, Loss: 0.1216351762\n",
      "14:47:13.207 [INFO] Epoch: 150, Loss: 0.1146249920\n",
      "14:47:13.462 [INFO] Epoch: 160, Loss: 0.1272899210\n",
      "14:47:13.688 [INFO] Epoch: 170, Loss: 0.1256502569\n",
      "14:47:13.925 [INFO] Epoch: 180, Loss: 0.1192595065\n",
      "14:47:14.144 [INFO] Epoch: 190, Loss: 0.1250004768\n",
      "14:47:14.359 [INFO] Epoch: 200, Loss: 0.1145179123\n",
      "14:47:14.606 [INFO] Epoch: 210, Loss: 0.1188367307\n",
      "14:47:14.847 [INFO] Epoch: 220, Loss: 0.1094774157\n",
      "14:47:15.910 [INFO] Epoch: 230, Loss: 0.1152252480\n",
      "14:47:15.329 [INFO] Epoch: 240, Loss: 0.1180267930\n",
      "14:47:15.590 [INFO] Epoch: 250, Loss: 0.1163273528\n",
      "14:47:15.752 [INFO] Epoch: 256, Loss: 0.1269545257\n",
      "14:47:15.753 [INFO] Pruning weights (19 / 62)\n",
      "14:47:15.797 [INFO] Shed 0.12506844103336334 weight\n",
      "14:47:15.867 [INFO] Constructed symbolic model\n",
      "14:47:16.583 [INFO] Constructed loss equation\n",
      "14:47:17.974 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:47:21.150 [INFO] Epoch: 1, Loss: 0.3181585073\n",
      "14:47:21.230 [INFO] Epoch: 10, Loss: 0.1178628206\n",
      "14:47:21.466 [INFO] Epoch: 20, Loss: 0.1336665750\n",
      "14:47:21.701 [INFO] Epoch: 30, Loss: 0.1136051714\n",
      "14:47:21.966 [INFO] Epoch: 40, Loss: 0.1231384575\n",
      "14:47:22.194 [INFO] Epoch: 50, Loss: 0.1220493168\n",
      "14:47:22.415 [INFO] Epoch: 60, Loss: 0.1178209856\n",
      "14:47:22.641 [INFO] Epoch: 70, Loss: 0.1236192882\n",
      "14:47:22.924 [INFO] Epoch: 80, Loss: 0.1185902804\n",
      "14:47:23.169 [INFO] Epoch: 90, Loss: 0.1118137315\n",
      "14:47:23.401 [INFO] Epoch: 100, Loss: 0.1236168519\n",
      "14:47:23.649 [INFO] Epoch: 110, Loss: 0.1200074777\n",
      "14:47:23.899 [INFO] Epoch: 120, Loss: 0.1210358068\n",
      "14:47:24.141 [INFO] Epoch: 130, Loss: 0.1355393827\n",
      "14:47:24.394 [INFO] Epoch: 140, Loss: 0.1128436476\n",
      "14:47:24.649 [INFO] Epoch: 150, Loss: 0.1181501299\n",
      "14:47:24.893 [INFO] Epoch: 160, Loss: 0.1216479987\n",
      "14:47:25.145 [INFO] Epoch: 170, Loss: 0.1152630225\n",
      "14:47:25.392 [INFO] Epoch: 180, Loss: 0.1144463569\n",
      "14:47:25.624 [INFO] Epoch: 190, Loss: 0.1098185182\n",
      "14:47:25.873 [INFO] Epoch: 200, Loss: 0.1243233383\n",
      "14:47:26.165 [INFO] Epoch: 210, Loss: 0.1195204258\n",
      "14:47:26.667 [INFO] Epoch: 220, Loss: 0.1065310240\n",
      "14:47:27.790 [INFO] Epoch: 230, Loss: 0.1330457628\n",
      "14:47:27.366 [INFO] Epoch: 240, Loss: 0.1158901751\n",
      "14:47:27.717 [INFO] Epoch: 250, Loss: 0.1159173846\n",
      "14:47:27.973 [INFO] Epoch: 256, Loss: 0.1150964126\n",
      "14:47:27.974 [INFO] Pruning weights (20 / 62)\n",
      "14:47:28.450 [INFO] Shed 0.4078228771686554 weight\n",
      "14:47:28.123 [INFO] Constructed symbolic model\n",
      "14:47:28.984 [INFO] Constructed loss equation\n",
      "14:47:30.484 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:47:34.129 [INFO] Epoch: 1, Loss: 0.4352279007\n",
      "14:47:34.392 [INFO] Epoch: 10, Loss: 0.1171709597\n",
      "14:47:34.770 [INFO] Epoch: 20, Loss: 0.1226444319\n",
      "14:47:35.176 [INFO] Epoch: 30, Loss: 0.1185462996\n",
      "14:47:35.582 [INFO] Epoch: 40, Loss: 0.1193382591\n",
      "14:47:35.991 [INFO] Epoch: 50, Loss: 0.1246660054\n",
      "14:47:36.394 [INFO] Epoch: 60, Loss: 0.1305027306\n",
      "14:47:36.816 [INFO] Epoch: 70, Loss: 0.1159239784\n",
      "14:47:37.175 [INFO] Epoch: 80, Loss: 0.1190404296\n",
      "14:47:37.534 [INFO] Epoch: 90, Loss: 0.1164181978\n",
      "14:47:38.200 [INFO] Epoch: 100, Loss: 0.1209814250\n",
      "14:47:38.350 [INFO] Epoch: 110, Loss: 0.1186937019\n",
      "14:47:38.650 [INFO] Epoch: 120, Loss: 0.1205518618\n",
      "14:47:39.160 [INFO] Epoch: 130, Loss: 0.1237960085\n",
      "14:47:39.367 [INFO] Epoch: 140, Loss: 0.1234067082\n",
      "14:47:39.750 [INFO] Epoch: 150, Loss: 0.1235588491\n",
      "14:47:40.510 [INFO] Epoch: 160, Loss: 0.1161535904\n",
      "14:47:40.351 [INFO] Epoch: 170, Loss: 0.1243157536\n",
      "14:47:40.753 [INFO] Epoch: 180, Loss: 0.1375665069\n",
      "14:47:41.176 [INFO] Epoch: 190, Loss: 0.1171663553\n",
      "14:47:41.593 [INFO] Epoch: 200, Loss: 0.1151745841\n",
      "14:47:41.996 [INFO] Epoch: 210, Loss: 0.1234808415\n",
      "14:47:42.397 [INFO] Epoch: 220, Loss: 0.1184088737\n",
      "14:47:42.818 [INFO] Epoch: 230, Loss: 0.1185662448\n",
      "14:47:43.232 [INFO] Epoch: 240, Loss: 0.1196955889\n",
      "14:47:43.625 [INFO] Epoch: 250, Loss: 0.1187939793\n",
      "14:47:43.855 [INFO] Epoch: 256, Loss: 0.1154452786\n",
      "14:47:43.855 [INFO] Pruning weights (21 / 62)\n",
      "14:47:43.931 [INFO] Shed 0.0009376195957884192 weight\n",
      "14:47:44.460 [INFO] Constructed symbolic model\n",
      "14:47:44.943 [INFO] Constructed loss equation\n",
      "14:47:45.942 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:47:48.814 [INFO] Epoch: 1, Loss: 0.3094827235\n",
      "14:47:49.450 [INFO] Epoch: 10, Loss: 0.1212352961\n",
      "14:47:49.330 [INFO] Epoch: 20, Loss: 0.1255806535\n",
      "14:47:49.653 [INFO] Epoch: 30, Loss: 0.1199853867\n",
      "14:47:49.895 [INFO] Epoch: 40, Loss: 0.1214258149\n",
      "14:47:50.105 [INFO] Epoch: 50, Loss: 0.1184737161\n",
      "14:47:50.315 [INFO] Epoch: 60, Loss: 0.1223991737\n",
      "14:47:50.528 [INFO] Epoch: 70, Loss: 0.1318979710\n",
      "14:47:50.772 [INFO] Epoch: 80, Loss: 0.1226292923\n",
      "14:47:51.400 [INFO] Epoch: 90, Loss: 0.1243893802\n",
      "14:47:51.213 [INFO] Epoch: 100, Loss: 0.1257613003\n",
      "14:47:51.477 [INFO] Epoch: 110, Loss: 0.1253829449\n",
      "14:47:51.701 [INFO] Epoch: 120, Loss: 0.1242466420\n",
      "14:47:51.982 [INFO] Epoch: 130, Loss: 0.1179272011\n",
      "14:47:52.201 [INFO] Epoch: 140, Loss: 0.1181713194\n",
      "14:47:52.401 [INFO] Epoch: 150, Loss: 0.1139913797\n",
      "14:47:52.630 [INFO] Epoch: 160, Loss: 0.1297072619\n",
      "14:47:52.833 [INFO] Epoch: 170, Loss: 0.1226088405\n",
      "14:47:53.440 [INFO] Epoch: 180, Loss: 0.1117645502\n",
      "14:47:53.265 [INFO] Epoch: 190, Loss: 0.1220691800\n",
      "14:47:53.470 [INFO] Epoch: 200, Loss: 0.1087163687\n",
      "14:47:53.676 [INFO] Epoch: 210, Loss: 0.1269791424\n",
      "14:47:53.894 [INFO] Epoch: 220, Loss: 0.1112174392\n",
      "14:47:54.109 [INFO] Epoch: 230, Loss: 0.1186210960\n",
      "14:47:54.343 [INFO] Epoch: 240, Loss: 0.1208215207\n",
      "14:47:54.624 [INFO] Epoch: 250, Loss: 0.1143649518\n",
      "14:47:54.757 [INFO] Epoch: 256, Loss: 0.1155727655\n",
      "14:47:54.758 [INFO] Pruning weights (22 / 62)\n",
      "14:47:54.836 [INFO] Shed 0.0008573891245760024 weight\n",
      "14:47:54.949 [INFO] Constructed symbolic model\n",
      "14:47:55.644 [INFO] Constructed loss equation\n",
      "14:47:56.860 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:47:59.583 [INFO] Epoch: 1, Loss: 0.2781943977\n",
      "14:47:59.765 [INFO] Epoch: 10, Loss: 0.1232265383\n",
      "14:47:59.968 [INFO] Epoch: 20, Loss: 0.1258414239\n",
      "14:48:00.178 [INFO] Epoch: 30, Loss: 0.1190029085\n",
      "14:48:00.372 [INFO] Epoch: 40, Loss: 0.1231930852\n",
      "14:48:00.609 [INFO] Epoch: 50, Loss: 0.1166435927\n",
      "14:48:00.854 [INFO] Epoch: 60, Loss: 0.1209914461\n",
      "14:48:01.850 [INFO] Epoch: 70, Loss: 0.1203303486\n",
      "14:48:01.318 [INFO] Epoch: 80, Loss: 0.1157042533\n",
      "14:48:01.531 [INFO] Epoch: 90, Loss: 0.1212203801\n",
      "14:48:01.747 [INFO] Epoch: 100, Loss: 0.1172145307\n",
      "14:48:01.952 [INFO] Epoch: 110, Loss: 0.1208207905\n",
      "14:48:02.153 [INFO] Epoch: 120, Loss: 0.1213616729\n",
      "14:48:02.365 [INFO] Epoch: 130, Loss: 0.1210729033\n",
      "14:48:02.579 [INFO] Epoch: 140, Loss: 0.1178868711\n",
      "14:48:02.797 [INFO] Epoch: 150, Loss: 0.1179913133\n",
      "14:48:03.120 [INFO] Epoch: 160, Loss: 0.1271566749\n",
      "14:48:03.227 [INFO] Epoch: 170, Loss: 0.1151944324\n",
      "14:48:03.441 [INFO] Epoch: 180, Loss: 0.1160636693\n",
      "14:48:03.662 [INFO] Epoch: 190, Loss: 0.1157241166\n",
      "14:48:03.881 [INFO] Epoch: 200, Loss: 0.1266603619\n",
      "14:48:04.950 [INFO] Epoch: 210, Loss: 0.1173234582\n",
      "14:48:04.340 [INFO] Epoch: 220, Loss: 0.1128051430\n",
      "14:48:04.565 [INFO] Epoch: 230, Loss: 0.1190586090\n",
      "14:48:04.788 [INFO] Epoch: 240, Loss: 0.1162011772\n",
      "14:48:05.700 [INFO] Epoch: 250, Loss: 0.1078733951\n",
      "14:48:05.230 [INFO] Epoch: 256, Loss: 0.1149247065\n",
      "14:48:05.231 [INFO] Pruning weights (23 / 62)\n",
      "14:48:05.271 [INFO] Shed 0.0023281921166926622 weight\n",
      "14:48:05.333 [INFO] Constructed symbolic model\n",
      "14:48:05.969 [INFO] Constructed loss equation\n",
      "14:48:06.849 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:09.380 [INFO] Epoch: 1, Loss: 0.2322299033\n",
      "14:48:09.561 [INFO] Epoch: 10, Loss: 0.1239749789\n",
      "14:48:09.769 [INFO] Epoch: 20, Loss: 0.1217930317\n",
      "14:48:09.984 [INFO] Epoch: 30, Loss: 0.1205846593\n",
      "14:48:10.195 [INFO] Epoch: 40, Loss: 0.1172609702\n",
      "14:48:10.408 [INFO] Epoch: 50, Loss: 0.1276467443\n",
      "14:48:10.630 [INFO] Epoch: 60, Loss: 0.1251858771\n",
      "14:48:10.845 [INFO] Epoch: 70, Loss: 0.1203654706\n",
      "14:48:11.470 [INFO] Epoch: 80, Loss: 0.1218842864\n",
      "14:48:11.246 [INFO] Epoch: 90, Loss: 0.1338635385\n",
      "14:48:11.463 [INFO] Epoch: 100, Loss: 0.1137739122\n",
      "14:48:11.673 [INFO] Epoch: 110, Loss: 0.1122265607\n",
      "14:48:11.881 [INFO] Epoch: 120, Loss: 0.1242173165\n",
      "14:48:12.860 [INFO] Epoch: 130, Loss: 0.1258652806\n",
      "14:48:12.291 [INFO] Epoch: 140, Loss: 0.1097171754\n",
      "14:48:12.490 [INFO] Epoch: 150, Loss: 0.1199515834\n",
      "14:48:12.701 [INFO] Epoch: 160, Loss: 0.1217083186\n",
      "14:48:12.903 [INFO] Epoch: 170, Loss: 0.1102709472\n",
      "14:48:13.116 [INFO] Epoch: 180, Loss: 0.1219872534\n",
      "14:48:13.328 [INFO] Epoch: 190, Loss: 0.1149297804\n",
      "14:48:13.526 [INFO] Epoch: 200, Loss: 0.1142907068\n",
      "14:48:13.758 [INFO] Epoch: 210, Loss: 0.1181012467\n",
      "14:48:13.968 [INFO] Epoch: 220, Loss: 0.1140209809\n",
      "14:48:14.171 [INFO] Epoch: 230, Loss: 0.1127925962\n",
      "14:48:14.367 [INFO] Epoch: 240, Loss: 0.1094475091\n",
      "14:48:14.569 [INFO] Epoch: 250, Loss: 0.1159985736\n",
      "14:48:14.701 [INFO] Epoch: 256, Loss: 0.1173901781\n",
      "14:48:14.702 [INFO] Pruning weights (24 / 62)\n",
      "14:48:14.742 [INFO] Shed 0.0003046329948119819 weight\n",
      "14:48:14.788 [INFO] Constructed symbolic model\n",
      "14:48:15.241 [INFO] Constructed loss equation\n",
      "14:48:16.148 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:18.710 [INFO] Epoch: 1, Loss: 0.7791779041\n",
      "14:48:18.899 [INFO] Epoch: 10, Loss: 0.1238509566\n",
      "14:48:19.124 [INFO] Epoch: 20, Loss: 0.1238277927\n",
      "14:48:19.346 [INFO] Epoch: 30, Loss: 0.1293865293\n",
      "14:48:19.555 [INFO] Epoch: 40, Loss: 0.1180955917\n",
      "14:48:19.778 [INFO] Epoch: 50, Loss: 0.1151852980\n",
      "14:48:20.700 [INFO] Epoch: 60, Loss: 0.1211563051\n",
      "14:48:20.241 [INFO] Epoch: 70, Loss: 0.1273324937\n",
      "14:48:20.481 [INFO] Epoch: 80, Loss: 0.1137860417\n",
      "14:48:20.706 [INFO] Epoch: 90, Loss: 0.1203926057\n",
      "14:48:20.937 [INFO] Epoch: 100, Loss: 0.1184985489\n",
      "14:48:21.305 [INFO] Epoch: 110, Loss: 0.1175234318\n",
      "14:48:21.562 [INFO] Epoch: 120, Loss: 0.1220861077\n",
      "14:48:21.798 [INFO] Epoch: 130, Loss: 0.1171995327\n",
      "14:48:22.320 [INFO] Epoch: 140, Loss: 0.1146051064\n",
      "14:48:22.276 [INFO] Epoch: 150, Loss: 0.1093718410\n",
      "14:48:22.504 [INFO] Epoch: 160, Loss: 0.1167193428\n",
      "14:48:22.755 [INFO] Epoch: 170, Loss: 0.1109155864\n",
      "14:48:23.100 [INFO] Epoch: 180, Loss: 0.1189250275\n",
      "14:48:23.299 [INFO] Epoch: 190, Loss: 0.1081414372\n",
      "14:48:23.556 [INFO] Epoch: 200, Loss: 0.1057757288\n",
      "14:48:23.819 [INFO] Epoch: 210, Loss: 0.1193802208\n",
      "14:48:24.570 [INFO] Epoch: 220, Loss: 0.1146278754\n",
      "14:48:24.272 [INFO] Epoch: 230, Loss: 0.1149069369\n",
      "14:48:24.486 [INFO] Epoch: 240, Loss: 0.1134579033\n",
      "14:48:24.716 [INFO] Epoch: 250, Loss: 0.1195853800\n",
      "14:48:24.833 [INFO] Epoch: 256, Loss: 0.1124324799\n",
      "14:48:24.834 [INFO] Pruning weights (25 / 62)\n",
      "14:48:24.874 [INFO] Shed 0.0014462119434028864 weight\n",
      "14:48:24.933 [INFO] Constructed symbolic model\n",
      "14:48:25.481 [INFO] Constructed loss equation\n",
      "14:48:26.274 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:29.399 [INFO] Epoch: 1, Loss: 0.3488183618\n",
      "14:48:29.744 [INFO] Epoch: 10, Loss: 0.1304246932\n",
      "14:48:30.350 [INFO] Epoch: 20, Loss: 0.1178313792\n",
      "14:48:30.314 [INFO] Epoch: 30, Loss: 0.1222333163\n",
      "14:48:30.607 [INFO] Epoch: 40, Loss: 0.1250824034\n",
      "14:48:30.843 [INFO] Epoch: 50, Loss: 0.1251553893\n",
      "14:48:31.137 [INFO] Epoch: 60, Loss: 0.1162959784\n",
      "14:48:31.420 [INFO] Epoch: 70, Loss: 0.1267799288\n",
      "14:48:31.722 [INFO] Epoch: 80, Loss: 0.1221203208\n",
      "14:48:32.219 [INFO] Epoch: 90, Loss: 0.1211539656\n",
      "14:48:32.589 [INFO] Epoch: 100, Loss: 0.1189645305\n",
      "14:48:32.856 [INFO] Epoch: 110, Loss: 0.1142198965\n",
      "14:48:33.183 [INFO] Epoch: 120, Loss: 0.1177576184\n",
      "14:48:33.466 [INFO] Epoch: 130, Loss: 0.1189114973\n",
      "14:48:33.674 [INFO] Epoch: 140, Loss: 0.1194090396\n",
      "14:48:33.893 [INFO] Epoch: 150, Loss: 0.1130345389\n",
      "14:48:34.123 [INFO] Epoch: 160, Loss: 0.1138295531\n",
      "14:48:34.354 [INFO] Epoch: 170, Loss: 0.1105582714\n",
      "14:48:34.577 [INFO] Epoch: 180, Loss: 0.1128537431\n",
      "14:48:34.805 [INFO] Epoch: 190, Loss: 0.1126843467\n",
      "14:48:35.230 [INFO] Epoch: 200, Loss: 0.1185441986\n",
      "14:48:35.231 [INFO] Epoch: 210, Loss: 0.1124039590\n",
      "14:48:35.444 [INFO] Epoch: 220, Loss: 0.1144426912\n",
      "14:48:35.654 [INFO] Epoch: 230, Loss: 0.1140950397\n",
      "14:48:35.862 [INFO] Epoch: 240, Loss: 0.1152641773\n",
      "14:48:36.760 [INFO] Epoch: 250, Loss: 0.1130415425\n",
      "14:48:36.223 [INFO] Epoch: 256, Loss: 0.1102184728\n",
      "14:48:36.224 [INFO] Pruning weights (26 / 62)\n",
      "14:48:36.267 [INFO] Shed 0.003614820772781968 weight\n",
      "14:48:36.318 [INFO] Constructed symbolic model\n",
      "14:48:36.805 [INFO] Constructed loss equation\n",
      "14:48:37.461 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:39.787 [INFO] Epoch: 1, Loss: 0.2400881648\n",
      "14:48:40.800 [INFO] Epoch: 10, Loss: 0.1294011325\n",
      "14:48:40.217 [INFO] Epoch: 20, Loss: 0.1107716560\n",
      "14:48:40.428 [INFO] Epoch: 30, Loss: 0.1173982173\n",
      "14:48:40.642 [INFO] Epoch: 40, Loss: 0.1192162931\n",
      "14:48:40.856 [INFO] Epoch: 50, Loss: 0.1277205199\n",
      "14:48:41.690 [INFO] Epoch: 60, Loss: 0.1102325991\n",
      "14:48:41.278 [INFO] Epoch: 70, Loss: 0.1132659763\n",
      "14:48:41.487 [INFO] Epoch: 80, Loss: 0.1196346283\n",
      "14:48:41.708 [INFO] Epoch: 90, Loss: 0.1245775297\n",
      "14:48:41.920 [INFO] Epoch: 100, Loss: 0.1230883002\n",
      "14:48:42.140 [INFO] Epoch: 110, Loss: 0.1132784784\n",
      "14:48:42.360 [INFO] Epoch: 120, Loss: 0.1129090339\n",
      "14:48:42.570 [INFO] Epoch: 130, Loss: 0.1179381758\n",
      "14:48:42.778 [INFO] Epoch: 140, Loss: 0.1114177033\n",
      "14:48:43.200 [INFO] Epoch: 150, Loss: 0.1165871918\n",
      "14:48:43.211 [INFO] Epoch: 160, Loss: 0.1149332076\n",
      "14:48:43.421 [INFO] Epoch: 170, Loss: 0.1171229109\n",
      "14:48:43.638 [INFO] Epoch: 180, Loss: 0.1158645675\n",
      "14:48:43.839 [INFO] Epoch: 190, Loss: 0.1217162162\n",
      "14:48:44.360 [INFO] Epoch: 200, Loss: 0.1241048649\n",
      "14:48:44.232 [INFO] Epoch: 210, Loss: 0.1189005673\n",
      "14:48:44.450 [INFO] Epoch: 220, Loss: 0.1206994355\n",
      "14:48:44.694 [INFO] Epoch: 230, Loss: 0.1183438525\n",
      "14:48:44.958 [INFO] Epoch: 240, Loss: 0.1184573993\n",
      "14:48:45.164 [INFO] Epoch: 250, Loss: 0.1139815748\n",
      "14:48:45.293 [INFO] Epoch: 256, Loss: 0.1177302599\n",
      "14:48:45.294 [INFO] Pruning weights (27 / 62)\n",
      "14:48:45.333 [INFO] Shed 0.2222186028957367 weight\n",
      "14:48:45.378 [INFO] Constructed symbolic model\n",
      "14:48:45.750 [INFO] Constructed loss equation\n",
      "14:48:46.259 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:49.174 [INFO] Epoch: 1, Loss: 11.0531883240\n",
      "14:48:49.396 [INFO] Epoch: 10, Loss: 0.3473858237\n",
      "14:48:49.641 [INFO] Epoch: 20, Loss: 0.1516238153\n",
      "14:48:49.860 [INFO] Epoch: 30, Loss: 0.1338258088\n",
      "14:48:50.800 [INFO] Epoch: 40, Loss: 0.1348951459\n",
      "14:48:50.297 [INFO] Epoch: 50, Loss: 0.1351848990\n",
      "14:48:50.507 [INFO] Epoch: 60, Loss: 0.1359541714\n",
      "14:48:50.743 [INFO] Epoch: 70, Loss: 0.1186910719\n",
      "14:48:50.958 [INFO] Epoch: 80, Loss: 0.1532681733\n",
      "14:48:51.180 [INFO] Epoch: 90, Loss: 0.1476315856\n",
      "14:48:51.371 [INFO] Epoch: 100, Loss: 0.1444325447\n",
      "14:48:51.599 [INFO] Epoch: 110, Loss: 0.1355458051\n",
      "14:48:51.819 [INFO] Epoch: 120, Loss: 0.1354404092\n",
      "14:48:52.340 [INFO] Epoch: 130, Loss: 0.1401110590\n",
      "14:48:52.238 [INFO] Epoch: 140, Loss: 0.1218670011\n",
      "14:48:52.478 [INFO] Epoch: 150, Loss: 0.1390681118\n",
      "14:48:52.707 [INFO] Epoch: 160, Loss: 0.1272152513\n",
      "14:48:52.964 [INFO] Epoch: 170, Loss: 0.1284376085\n",
      "14:48:53.215 [INFO] Epoch: 180, Loss: 0.1267700493\n",
      "14:48:53.454 [INFO] Epoch: 190, Loss: 0.1313687712\n",
      "14:48:53.709 [INFO] Epoch: 200, Loss: 0.1308659613\n",
      "14:48:53.930 [INFO] Epoch: 210, Loss: 0.1202654615\n",
      "14:48:54.135 [INFO] Epoch: 220, Loss: 0.1227756217\n",
      "14:48:54.349 [INFO] Epoch: 230, Loss: 0.1306391954\n",
      "14:48:54.565 [INFO] Epoch: 240, Loss: 0.1261568666\n",
      "14:48:54.797 [INFO] Epoch: 250, Loss: 0.1233861297\n",
      "14:48:54.941 [INFO] Epoch: 256, Loss: 0.1278876960\n",
      "14:48:54.942 [INFO] Pruning weights (28 / 62)\n",
      "14:48:54.977 [INFO] Shed 0.000656197895295918 weight\n",
      "14:48:55.560 [INFO] Constructed symbolic model\n",
      "14:48:55.370 [INFO] Constructed loss equation\n",
      "14:48:55.853 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:48:58.424 [INFO] Epoch: 1, Loss: 0.5621051788\n",
      "14:48:58.634 [INFO] Epoch: 10, Loss: 0.1345270425\n",
      "14:48:58.884 [INFO] Epoch: 20, Loss: 0.1428498179\n",
      "14:48:59.211 [INFO] Epoch: 30, Loss: 0.1395401061\n",
      "14:48:59.532 [INFO] Epoch: 40, Loss: 0.1251850575\n",
      "14:48:59.823 [INFO] Epoch: 50, Loss: 0.1713035405\n",
      "14:49:00.192 [INFO] Epoch: 60, Loss: 0.1299498081\n",
      "14:49:00.439 [INFO] Epoch: 70, Loss: 0.1306965351\n",
      "14:49:00.659 [INFO] Epoch: 80, Loss: 0.1152143851\n",
      "14:49:00.875 [INFO] Epoch: 90, Loss: 0.1307712495\n",
      "14:49:01.910 [INFO] Epoch: 100, Loss: 0.1237865537\n",
      "14:49:01.310 [INFO] Epoch: 110, Loss: 0.1322127581\n",
      "14:49:01.526 [INFO] Epoch: 120, Loss: 0.1311901808\n",
      "14:49:01.757 [INFO] Epoch: 130, Loss: 0.1308693439\n",
      "14:49:01.989 [INFO] Epoch: 140, Loss: 0.1431107968\n",
      "14:49:02.220 [INFO] Epoch: 150, Loss: 0.1336535215\n",
      "14:49:02.439 [INFO] Epoch: 160, Loss: 0.1207177266\n",
      "14:49:02.665 [INFO] Epoch: 170, Loss: 0.1244955361\n",
      "14:49:02.897 [INFO] Epoch: 180, Loss: 0.1232487634\n",
      "14:49:03.121 [INFO] Epoch: 190, Loss: 0.1156889647\n",
      "14:49:03.351 [INFO] Epoch: 200, Loss: 0.1311590374\n",
      "14:49:03.572 [INFO] Epoch: 210, Loss: 0.1297137290\n",
      "14:49:03.790 [INFO] Epoch: 220, Loss: 0.1243005320\n",
      "14:49:04.500 [INFO] Epoch: 230, Loss: 0.1368151307\n",
      "14:49:04.226 [INFO] Epoch: 240, Loss: 0.1215561777\n",
      "14:49:04.442 [INFO] Epoch: 250, Loss: 0.1265331507\n",
      "14:49:04.576 [INFO] Epoch: 256, Loss: 0.1160993129\n",
      "14:49:04.577 [INFO] Pruning weights (29 / 62)\n",
      "14:49:04.628 [INFO] Shed 0.002891410840675235 weight\n",
      "14:49:04.710 [INFO] Constructed symbolic model\n",
      "14:49:04.932 [INFO] Constructed loss equation\n",
      "14:49:05.213 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:49:07.774 [INFO] Epoch: 1, Loss: 1.0239851475\n",
      "14:49:07.987 [INFO] Epoch: 10, Loss: 0.1344882846\n",
      "14:49:08.203 [INFO] Epoch: 20, Loss: 0.1274271458\n",
      "14:49:08.428 [INFO] Epoch: 30, Loss: 0.1283059716\n",
      "14:49:08.658 [INFO] Epoch: 40, Loss: 0.1241463125\n",
      "14:49:08.888 [INFO] Epoch: 50, Loss: 0.1292647421\n",
      "14:49:09.101 [INFO] Epoch: 60, Loss: 0.1284888089\n",
      "14:49:09.315 [INFO] Epoch: 70, Loss: 0.1365951598\n",
      "14:49:09.532 [INFO] Epoch: 80, Loss: 0.1534497887\n",
      "14:49:09.747 [INFO] Epoch: 90, Loss: 0.1409840584\n",
      "14:49:09.963 [INFO] Epoch: 100, Loss: 0.1290177852\n",
      "14:49:10.175 [INFO] Epoch: 110, Loss: 0.1601739824\n",
      "14:49:10.397 [INFO] Epoch: 120, Loss: 0.1335566044\n",
      "14:49:10.612 [INFO] Epoch: 130, Loss: 0.1301177740\n",
      "14:49:10.838 [INFO] Epoch: 140, Loss: 0.1304529011\n",
      "14:49:11.680 [INFO] Epoch: 150, Loss: 0.1219473109\n",
      "14:49:11.289 [INFO] Epoch: 160, Loss: 0.1218636706\n",
      "14:49:11.534 [INFO] Epoch: 170, Loss: 0.1343320608\n",
      "14:49:11.755 [INFO] Epoch: 180, Loss: 0.1302152723\n",
      "14:49:11.974 [INFO] Epoch: 190, Loss: 0.1438476592\n",
      "14:49:12.193 [INFO] Epoch: 200, Loss: 0.1340782344\n",
      "14:49:12.406 [INFO] Epoch: 210, Loss: 0.1238521710\n",
      "14:49:12.625 [INFO] Epoch: 220, Loss: 0.1265035272\n",
      "14:49:12.857 [INFO] Epoch: 230, Loss: 0.1228390858\n",
      "14:49:13.740 [INFO] Epoch: 240, Loss: 0.1238766760\n",
      "14:49:13.290 [INFO] Epoch: 250, Loss: 0.1322878897\n",
      "14:49:13.421 [INFO] Epoch: 256, Loss: 0.1219966263\n",
      "14:49:13.421 [INFO] Pruning weights (30 / 62)\n",
      "14:49:13.464 [INFO] Shed 0.005811015609651804 weight\n",
      "14:49:13.496 [INFO] Constructed symbolic model\n",
      "14:49:13.768 [INFO] Constructed loss equation\n",
      "14:49:14.189 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:49:16.285 [INFO] Epoch: 1, Loss: 0.5778954029\n",
      "14:49:16.476 [INFO] Epoch: 10, Loss: 0.1310619414\n",
      "14:49:16.686 [INFO] Epoch: 20, Loss: 0.1408624798\n",
      "14:49:16.915 [INFO] Epoch: 30, Loss: 0.1387625784\n",
      "14:49:17.146 [INFO] Epoch: 40, Loss: 0.1361803412\n",
      "14:49:17.369 [INFO] Epoch: 50, Loss: 0.1338857263\n",
      "14:49:17.584 [INFO] Epoch: 60, Loss: 0.1362797618\n",
      "14:49:17.799 [INFO] Epoch: 70, Loss: 0.1310892105\n",
      "14:49:18.270 [INFO] Epoch: 80, Loss: 0.1238322631\n",
      "14:49:18.236 [INFO] Epoch: 90, Loss: 0.1349850893\n",
      "14:49:18.455 [INFO] Epoch: 100, Loss: 0.1326376200\n",
      "14:49:18.662 [INFO] Epoch: 110, Loss: 0.1369865090\n",
      "14:49:18.870 [INFO] Epoch: 120, Loss: 0.1279963106\n",
      "14:49:19.890 [INFO] Epoch: 130, Loss: 0.1395418495\n",
      "14:49:19.301 [INFO] Epoch: 140, Loss: 0.1211707741\n",
      "14:49:19.514 [INFO] Epoch: 150, Loss: 0.1233324856\n",
      "14:49:19.728 [INFO] Epoch: 160, Loss: 0.1314629912\n",
      "14:49:19.942 [INFO] Epoch: 170, Loss: 0.1267310530\n",
      "14:49:20.156 [INFO] Epoch: 180, Loss: 0.1206745356\n",
      "14:49:20.371 [INFO] Epoch: 190, Loss: 0.1253879219\n",
      "14:49:20.580 [INFO] Epoch: 200, Loss: 0.1276281923\n",
      "14:49:20.791 [INFO] Epoch: 210, Loss: 0.1283259988\n",
      "14:49:21.220 [INFO] Epoch: 220, Loss: 0.1227313951\n",
      "14:49:21.240 [INFO] Epoch: 230, Loss: 0.1215562299\n",
      "14:49:21.459 [INFO] Epoch: 240, Loss: 0.1228213832\n",
      "14:49:21.675 [INFO] Epoch: 250, Loss: 0.1248303950\n",
      "14:49:21.805 [INFO] Epoch: 256, Loss: 0.1240257844\n",
      "14:49:21.806 [INFO] Pruning weights (31 / 62)\n",
      "14:49:21.849 [INFO] Shed 0.0038935972843319178 weight\n",
      "14:49:21.886 [INFO] Constructed symbolic model\n",
      "14:49:22.184 [INFO] Constructed loss equation\n",
      "14:49:22.648 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:49:25.344 [INFO] Epoch: 1, Loss: 0.5249371529\n",
      "14:49:25.553 [INFO] Epoch: 10, Loss: 0.1431117356\n",
      "14:49:25.776 [INFO] Epoch: 20, Loss: 0.1365053505\n",
      "14:49:25.992 [INFO] Epoch: 30, Loss: 0.1530170739\n",
      "14:49:26.209 [INFO] Epoch: 40, Loss: 0.1376252174\n",
      "14:49:26.594 [INFO] Epoch: 50, Loss: 0.1303880066\n",
      "14:49:26.976 [INFO] Epoch: 60, Loss: 0.1314717531\n",
      "14:49:27.397 [INFO] Epoch: 70, Loss: 0.1290264130\n",
      "14:49:27.860 [INFO] Epoch: 80, Loss: 0.1386762559\n",
      "14:49:28.181 [INFO] Epoch: 90, Loss: 0.1467527747\n",
      "14:49:28.584 [INFO] Epoch: 100, Loss: 0.1219964474\n",
      "14:49:28.953 [INFO] Epoch: 110, Loss: 0.1222528219\n",
      "14:49:29.365 [INFO] Epoch: 120, Loss: 0.1299784482\n",
      "14:49:29.699 [INFO] Epoch: 130, Loss: 0.1278157532\n",
      "14:49:30.217 [INFO] Epoch: 140, Loss: 0.1196683422\n",
      "14:49:30.648 [INFO] Epoch: 150, Loss: 0.1281021833\n",
      "14:49:31.138 [INFO] Epoch: 160, Loss: 0.1218266189\n",
      "14:49:31.599 [INFO] Epoch: 170, Loss: 0.1293275058\n",
      "14:49:31.948 [INFO] Epoch: 180, Loss: 0.1239487827\n",
      "14:49:32.329 [INFO] Epoch: 190, Loss: 0.1234499663\n",
      "14:49:32.568 [INFO] Epoch: 200, Loss: 0.1256545484\n",
      "14:49:32.830 [INFO] Epoch: 210, Loss: 0.1234802008\n",
      "14:49:33.670 [INFO] Epoch: 220, Loss: 0.1247706190\n",
      "14:49:33.297 [INFO] Epoch: 230, Loss: 0.1205430329\n",
      "14:49:33.535 [INFO] Epoch: 240, Loss: 0.1227379367\n",
      "14:49:33.777 [INFO] Epoch: 250, Loss: 0.1346071064\n",
      "14:49:33.922 [INFO] Epoch: 256, Loss: 0.1260581613\n",
      "14:49:33.923 [INFO] Pruning weights (32 / 62)\n",
      "14:49:33.971 [INFO] Shed 0.0030835303477942944 weight\n",
      "14:49:34.170 [INFO] Constructed symbolic model\n",
      "14:49:34.323 [INFO] Constructed loss equation\n",
      "14:49:34.991 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:49:37.313 [INFO] Epoch: 1, Loss: 0.5650442839\n",
      "14:49:37.508 [INFO] Epoch: 10, Loss: 0.1391607523\n",
      "14:49:37.738 [INFO] Epoch: 20, Loss: 0.1373300552\n",
      "14:49:37.968 [INFO] Epoch: 30, Loss: 0.1239330694\n",
      "14:49:38.187 [INFO] Epoch: 40, Loss: 0.1599418968\n",
      "14:49:38.411 [INFO] Epoch: 50, Loss: 0.1302962303\n",
      "14:49:38.636 [INFO] Epoch: 60, Loss: 0.1303938329\n",
      "14:49:38.866 [INFO] Epoch: 70, Loss: 0.1317971498\n",
      "14:49:39.980 [INFO] Epoch: 80, Loss: 0.1389492154\n",
      "14:49:39.343 [INFO] Epoch: 90, Loss: 0.1351652890\n",
      "14:49:39.584 [INFO] Epoch: 100, Loss: 0.1216219366\n",
      "14:49:39.808 [INFO] Epoch: 110, Loss: 0.1418383420\n",
      "14:49:40.240 [INFO] Epoch: 120, Loss: 0.1271219999\n",
      "14:49:40.239 [INFO] Epoch: 130, Loss: 0.1286299527\n",
      "14:49:40.456 [INFO] Epoch: 140, Loss: 0.1202195138\n",
      "14:49:40.683 [INFO] Epoch: 150, Loss: 0.1256021708\n",
      "14:49:40.901 [INFO] Epoch: 160, Loss: 0.1340075433\n",
      "14:49:41.121 [INFO] Epoch: 170, Loss: 0.1271502376\n",
      "14:49:41.337 [INFO] Epoch: 180, Loss: 0.1225268319\n",
      "14:49:41.549 [INFO] Epoch: 190, Loss: 0.1265152246\n",
      "14:49:41.770 [INFO] Epoch: 200, Loss: 0.1204788536\n",
      "14:49:41.986 [INFO] Epoch: 210, Loss: 0.1271610260\n",
      "14:49:42.207 [INFO] Epoch: 220, Loss: 0.1211623102\n",
      "14:49:42.423 [INFO] Epoch: 230, Loss: 0.1220592260\n",
      "14:49:42.641 [INFO] Epoch: 240, Loss: 0.1207551286\n",
      "14:49:42.858 [INFO] Epoch: 250, Loss: 0.1317761838\n",
      "14:49:42.989 [INFO] Epoch: 256, Loss: 0.1216655523\n",
      "14:49:42.990 [INFO] Pruning weights (33 / 62)\n",
      "14:49:43.310 [INFO] Shed 0.008202506229281425 weight\n",
      "14:49:43.610 [INFO] Constructed symbolic model\n",
      "14:49:43.320 [INFO] Constructed loss equation\n",
      "14:49:43.726 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:49:45.955 [INFO] Epoch: 1, Loss: 0.5883409381\n",
      "14:49:46.180 [INFO] Epoch: 10, Loss: 0.1319370866\n",
      "14:49:46.431 [INFO] Epoch: 20, Loss: 0.1303689629\n",
      "14:49:46.665 [INFO] Epoch: 30, Loss: 0.1289400160\n",
      "14:49:46.892 [INFO] Epoch: 40, Loss: 0.1368159354\n",
      "14:49:47.145 [INFO] Epoch: 50, Loss: 0.1389179379\n",
      "14:49:47.422 [INFO] Epoch: 60, Loss: 0.1606277376\n",
      "14:49:47.675 [INFO] Epoch: 70, Loss: 0.1426714659\n",
      "14:49:47.966 [INFO] Epoch: 80, Loss: 0.1317963600\n",
      "14:49:48.261 [INFO] Epoch: 90, Loss: 0.1272103488\n",
      "14:49:48.525 [INFO] Epoch: 100, Loss: 0.1280563176\n",
      "14:49:48.802 [INFO] Epoch: 110, Loss: 0.1261060238\n",
      "14:49:49.309 [INFO] Epoch: 120, Loss: 0.1208656132\n",
      "14:49:49.573 [INFO] Epoch: 130, Loss: 0.1269738227\n",
      "14:49:49.800 [INFO] Epoch: 140, Loss: 0.1234893948\n",
      "14:49:50.970 [INFO] Epoch: 150, Loss: 0.1219173223\n",
      "14:49:50.376 [INFO] Epoch: 160, Loss: 0.1237728819\n",
      "14:49:50.664 [INFO] Epoch: 170, Loss: 0.1248806864\n",
      "14:49:50.929 [INFO] Epoch: 180, Loss: 0.1171810627\n",
      "14:49:51.330 [INFO] Epoch: 190, Loss: 0.1214658320\n",
      "14:49:51.692 [INFO] Epoch: 200, Loss: 0.1200582683\n",
      "14:49:52.183 [INFO] Epoch: 210, Loss: 0.1277970523\n",
      "14:49:52.682 [INFO] Epoch: 220, Loss: 0.1217654943\n",
      "14:49:53.180 [INFO] Epoch: 230, Loss: 0.1183304042\n",
      "14:49:53.461 [INFO] Epoch: 240, Loss: 0.1254157871\n",
      "14:49:53.988 [INFO] Epoch: 250, Loss: 0.1336506605\n",
      "14:49:54.255 [INFO] Epoch: 256, Loss: 0.1225592867\n",
      "14:49:54.256 [INFO] Pruning weights (34 / 62)\n",
      "14:49:54.323 [INFO] Shed 0.3984302282333374 weight\n",
      "14:49:54.376 [INFO] Constructed symbolic model\n",
      "14:49:54.846 [INFO] Constructed loss equation\n",
      "14:49:55.628 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:00.725 [INFO] Epoch: 1, Loss: 1.2093378305\n",
      "14:50:01.197 [INFO] Epoch: 10, Loss: 0.1670108140\n",
      "14:50:01.648 [INFO] Epoch: 20, Loss: 0.1385160983\n",
      "14:50:02.240 [INFO] Epoch: 30, Loss: 0.1337196231\n",
      "14:50:02.331 [INFO] Epoch: 40, Loss: 0.1388574243\n",
      "14:50:02.611 [INFO] Epoch: 50, Loss: 0.1312272549\n",
      "14:50:02.928 [INFO] Epoch: 60, Loss: 0.1452115476\n",
      "14:50:03.191 [INFO] Epoch: 70, Loss: 0.1318174154\n",
      "14:50:03.423 [INFO] Epoch: 80, Loss: 0.1271351725\n",
      "14:50:03.657 [INFO] Epoch: 90, Loss: 0.1292727888\n",
      "14:50:03.935 [INFO] Epoch: 100, Loss: 0.1283498406\n",
      "14:50:04.177 [INFO] Epoch: 110, Loss: 0.1288948357\n",
      "14:50:04.431 [INFO] Epoch: 120, Loss: 0.1222185642\n",
      "14:50:04.764 [INFO] Epoch: 130, Loss: 0.1307206601\n",
      "14:50:05.420 [INFO] Epoch: 140, Loss: 0.1380570531\n",
      "14:50:05.503 [INFO] Epoch: 150, Loss: 0.1233306527\n",
      "14:50:05.797 [INFO] Epoch: 160, Loss: 0.1252603531\n",
      "14:50:06.190 [INFO] Epoch: 170, Loss: 0.1243754327\n",
      "14:50:06.533 [INFO] Epoch: 180, Loss: 0.1272522509\n",
      "14:50:06.894 [INFO] Epoch: 190, Loss: 0.1286386251\n",
      "14:50:07.174 [INFO] Epoch: 200, Loss: 0.1219186708\n",
      "14:50:07.436 [INFO] Epoch: 210, Loss: 0.1238436848\n",
      "14:50:07.707 [INFO] Epoch: 220, Loss: 0.1172806323\n",
      "14:50:08.770 [INFO] Epoch: 230, Loss: 0.1172750741\n",
      "14:50:08.320 [INFO] Epoch: 240, Loss: 0.1215696856\n",
      "14:50:08.542 [INFO] Epoch: 250, Loss: 0.1241846085\n",
      "14:50:08.694 [INFO] Epoch: 256, Loss: 0.1247337908\n",
      "14:50:08.695 [INFO] Pruning weights (35 / 62)\n",
      "14:50:08.730 [INFO] Shed 0.000587774848099798 weight\n",
      "14:50:08.805 [INFO] Constructed symbolic model\n",
      "14:50:09.250 [INFO] Constructed loss equation\n",
      "14:50:09.468 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:12.108 [INFO] Epoch: 1, Loss: 0.2312025130\n",
      "14:50:12.740 [INFO] Epoch: 10, Loss: 0.1389101148\n",
      "14:50:13.357 [INFO] Epoch: 20, Loss: 0.1239966452\n",
      "14:50:13.967 [INFO] Epoch: 30, Loss: 0.1267084181\n",
      "14:50:14.272 [INFO] Epoch: 40, Loss: 0.1334223151\n",
      "14:50:14.553 [INFO] Epoch: 50, Loss: 0.1231177598\n",
      "14:50:14.803 [INFO] Epoch: 60, Loss: 0.1359874457\n",
      "14:50:15.105 [INFO] Epoch: 70, Loss: 0.1296887994\n",
      "14:50:15.351 [INFO] Epoch: 80, Loss: 0.1295146942\n",
      "14:50:15.639 [INFO] Epoch: 90, Loss: 0.1340897083\n",
      "14:50:16.116 [INFO] Epoch: 100, Loss: 0.1306766272\n",
      "14:50:16.461 [INFO] Epoch: 110, Loss: 0.1256004125\n",
      "14:50:16.816 [INFO] Epoch: 120, Loss: 0.1314595938\n",
      "14:50:17.690 [INFO] Epoch: 130, Loss: 0.1287507713\n",
      "14:50:17.414 [INFO] Epoch: 140, Loss: 0.1356931627\n",
      "14:50:17.778 [INFO] Epoch: 150, Loss: 0.1310240030\n",
      "14:50:18.306 [INFO] Epoch: 160, Loss: 0.1293233782\n",
      "14:50:18.616 [INFO] Epoch: 170, Loss: 0.1180659086\n",
      "14:50:18.885 [INFO] Epoch: 180, Loss: 0.1297276318\n",
      "14:50:19.117 [INFO] Epoch: 190, Loss: 0.1191123277\n",
      "14:50:19.351 [INFO] Epoch: 200, Loss: 0.1191183776\n",
      "14:50:19.579 [INFO] Epoch: 210, Loss: 0.1202609837\n",
      "14:50:19.814 [INFO] Epoch: 220, Loss: 0.1168774962\n",
      "14:50:20.151 [INFO] Epoch: 230, Loss: 0.1326531768\n",
      "14:50:20.529 [INFO] Epoch: 240, Loss: 0.1197838262\n",
      "14:50:20.893 [INFO] Epoch: 250, Loss: 0.1283059418\n",
      "14:50:21.820 [INFO] Epoch: 256, Loss: 0.1156193912\n",
      "14:50:21.830 [INFO] Pruning weights (36 / 62)\n",
      "14:50:21.129 [INFO] Shed 6.050957745173946e-05 weight\n",
      "14:50:21.195 [INFO] Constructed symbolic model\n",
      "14:50:21.413 [INFO] Constructed loss equation\n",
      "14:50:21.916 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:25.375 [INFO] Epoch: 1, Loss: 0.2852467895\n",
      "14:50:25.735 [INFO] Epoch: 10, Loss: 0.1293295026\n",
      "14:50:26.510 [INFO] Epoch: 20, Loss: 0.1213586926\n",
      "14:50:26.477 [INFO] Epoch: 30, Loss: 0.1308394372\n",
      "14:50:26.994 [INFO] Epoch: 40, Loss: 0.1289426386\n",
      "14:50:27.406 [INFO] Epoch: 50, Loss: 0.1343495846\n",
      "14:50:27.740 [INFO] Epoch: 60, Loss: 0.1196332425\n",
      "14:50:28.810 [INFO] Epoch: 70, Loss: 0.1269174814\n",
      "14:50:28.363 [INFO] Epoch: 80, Loss: 0.1276923865\n",
      "14:50:28.641 [INFO] Epoch: 90, Loss: 0.1239235103\n",
      "14:50:28.909 [INFO] Epoch: 100, Loss: 0.1217356026\n",
      "14:50:29.140 [INFO] Epoch: 110, Loss: 0.1291103214\n",
      "14:50:29.364 [INFO] Epoch: 120, Loss: 0.1327987313\n",
      "14:50:29.587 [INFO] Epoch: 130, Loss: 0.1212126687\n",
      "14:50:29.826 [INFO] Epoch: 140, Loss: 0.1268931329\n",
      "14:50:30.890 [INFO] Epoch: 150, Loss: 0.1265261769\n",
      "14:50:30.337 [INFO] Epoch: 160, Loss: 0.1271870285\n",
      "14:50:30.593 [INFO] Epoch: 170, Loss: 0.1277219653\n",
      "14:50:30.809 [INFO] Epoch: 180, Loss: 0.1157796830\n",
      "14:50:31.410 [INFO] Epoch: 190, Loss: 0.1217269972\n",
      "14:50:31.263 [INFO] Epoch: 200, Loss: 0.1242252514\n",
      "14:50:31.506 [INFO] Epoch: 210, Loss: 0.1238616258\n",
      "14:50:31.740 [INFO] Epoch: 220, Loss: 0.1214968041\n",
      "14:50:31.995 [INFO] Epoch: 230, Loss: 0.1233803853\n",
      "14:50:32.225 [INFO] Epoch: 240, Loss: 0.1312612146\n",
      "14:50:32.443 [INFO] Epoch: 250, Loss: 0.1297729611\n",
      "14:50:32.571 [INFO] Epoch: 256, Loss: 0.1257147789\n",
      "14:50:32.572 [INFO] Pruning weights (37 / 62)\n",
      "14:50:32.614 [INFO] Shed 0.004738965071737766 weight\n",
      "14:50:32.637 [INFO] Constructed symbolic model\n",
      "14:50:32.832 [INFO] Constructed loss equation\n",
      "14:50:33.123 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:35.160 [INFO] Epoch: 1, Loss: 0.3001345396\n",
      "14:50:35.383 [INFO] Epoch: 10, Loss: 0.1346620917\n",
      "14:50:35.605 [INFO] Epoch: 20, Loss: 0.1351700127\n",
      "14:50:35.824 [INFO] Epoch: 30, Loss: 0.1250048280\n",
      "14:50:36.380 [INFO] Epoch: 40, Loss: 0.1265631020\n",
      "14:50:36.253 [INFO] Epoch: 50, Loss: 0.1286693364\n",
      "14:50:36.464 [INFO] Epoch: 60, Loss: 0.1261583567\n",
      "14:50:36.715 [INFO] Epoch: 70, Loss: 0.1266602129\n",
      "14:50:37.111 [INFO] Epoch: 80, Loss: 0.1343978345\n",
      "14:50:37.413 [INFO] Epoch: 90, Loss: 0.1350353509\n",
      "14:50:37.683 [INFO] Epoch: 100, Loss: 0.1224979013\n",
      "14:50:37.963 [INFO] Epoch: 110, Loss: 0.1237407774\n",
      "14:50:38.264 [INFO] Epoch: 120, Loss: 0.1202857718\n",
      "14:50:38.565 [INFO] Epoch: 130, Loss: 0.1255545616\n",
      "14:50:38.881 [INFO] Epoch: 140, Loss: 0.1226607561\n",
      "14:50:39.146 [INFO] Epoch: 150, Loss: 0.1235403717\n",
      "14:50:39.418 [INFO] Epoch: 160, Loss: 0.1226857901\n",
      "14:50:39.690 [INFO] Epoch: 170, Loss: 0.1150812507\n",
      "14:50:39.952 [INFO] Epoch: 180, Loss: 0.1189861894\n",
      "14:50:40.188 [INFO] Epoch: 190, Loss: 0.1161395237\n",
      "14:50:40.408 [INFO] Epoch: 200, Loss: 0.1205421984\n",
      "14:50:40.634 [INFO] Epoch: 210, Loss: 0.1214513779\n",
      "14:50:40.863 [INFO] Epoch: 220, Loss: 0.1164330095\n",
      "14:50:41.170 [INFO] Epoch: 230, Loss: 0.1274121851\n",
      "14:50:41.445 [INFO] Epoch: 240, Loss: 0.1275846362\n",
      "14:50:41.769 [INFO] Epoch: 250, Loss: 0.1190335751\n",
      "14:50:42.600 [INFO] Epoch: 256, Loss: 0.1293064058\n",
      "14:50:42.620 [INFO] Pruning weights (38 / 62)\n",
      "14:50:42.119 [INFO] Shed 0.0020823930390179157 weight\n",
      "14:50:42.151 [INFO] Constructed symbolic model\n",
      "14:50:42.417 [INFO] Constructed loss equation\n",
      "14:50:42.876 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:45.355 [INFO] Epoch: 1, Loss: 0.3204908371\n",
      "14:50:45.587 [INFO] Epoch: 10, Loss: 0.1321669519\n",
      "14:50:45.837 [INFO] Epoch: 20, Loss: 0.1496175230\n",
      "14:50:46.690 [INFO] Epoch: 30, Loss: 0.1298537552\n",
      "14:50:46.303 [INFO] Epoch: 40, Loss: 0.1328404248\n",
      "14:50:46.545 [INFO] Epoch: 50, Loss: 0.1287795603\n",
      "14:50:46.815 [INFO] Epoch: 60, Loss: 0.1264564395\n",
      "14:50:47.100 [INFO] Epoch: 70, Loss: 0.1340076774\n",
      "14:50:47.330 [INFO] Epoch: 80, Loss: 0.1298018992\n",
      "14:50:47.582 [INFO] Epoch: 90, Loss: 0.1254564524\n",
      "14:50:47.848 [INFO] Epoch: 100, Loss: 0.1302915514\n",
      "14:50:48.920 [INFO] Epoch: 110, Loss: 0.1249967664\n",
      "14:50:48.355 [INFO] Epoch: 120, Loss: 0.1335185170\n",
      "14:50:48.605 [INFO] Epoch: 130, Loss: 0.1284335852\n",
      "14:50:48.860 [INFO] Epoch: 140, Loss: 0.1247455478\n",
      "14:50:49.117 [INFO] Epoch: 150, Loss: 0.1284853220\n",
      "14:50:49.353 [INFO] Epoch: 160, Loss: 0.1288447231\n",
      "14:50:49.591 [INFO] Epoch: 170, Loss: 0.1308973134\n",
      "14:50:49.811 [INFO] Epoch: 180, Loss: 0.1215405315\n",
      "14:50:50.220 [INFO] Epoch: 190, Loss: 0.1233799607\n",
      "14:50:50.245 [INFO] Epoch: 200, Loss: 0.1205780357\n",
      "14:50:50.460 [INFO] Epoch: 210, Loss: 0.1288798451\n",
      "14:50:50.678 [INFO] Epoch: 220, Loss: 0.1200620309\n",
      "14:50:50.910 [INFO] Epoch: 230, Loss: 0.1193286777\n",
      "14:50:51.143 [INFO] Epoch: 240, Loss: 0.1225202158\n",
      "14:50:51.366 [INFO] Epoch: 250, Loss: 0.1196569055\n",
      "14:50:51.512 [INFO] Epoch: 256, Loss: 0.1215040088\n",
      "14:50:51.512 [INFO] Pruning weights (39 / 62)\n",
      "14:50:51.559 [INFO] Shed 0.04034923389554024 weight\n",
      "14:50:51.579 [INFO] Constructed symbolic model\n",
      "14:50:51.791 [INFO] Constructed loss equation\n",
      "14:50:52.180 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:50:54.370 [INFO] Epoch: 1, Loss: 0.4654484689\n",
      "14:50:54.565 [INFO] Epoch: 10, Loss: 0.1317531317\n",
      "14:50:54.780 [INFO] Epoch: 20, Loss: 0.1262021959\n",
      "14:50:55.190 [INFO] Epoch: 30, Loss: 0.1289374828\n",
      "14:50:55.263 [INFO] Epoch: 40, Loss: 0.1312616765\n",
      "14:50:55.488 [INFO] Epoch: 50, Loss: 0.1292771697\n",
      "14:50:55.735 [INFO] Epoch: 60, Loss: 0.1261317730\n",
      "14:50:55.977 [INFO] Epoch: 70, Loss: 0.1190008447\n",
      "14:50:56.206 [INFO] Epoch: 80, Loss: 0.1177567989\n",
      "14:50:56.433 [INFO] Epoch: 90, Loss: 0.1232374758\n",
      "14:50:56.674 [INFO] Epoch: 100, Loss: 0.1259673387\n",
      "14:50:56.928 [INFO] Epoch: 110, Loss: 0.1223509610\n",
      "14:50:57.178 [INFO] Epoch: 120, Loss: 0.1242597550\n",
      "14:50:57.450 [INFO] Epoch: 130, Loss: 0.1244077235\n",
      "14:50:57.694 [INFO] Epoch: 140, Loss: 0.1277816296\n",
      "14:50:57.941 [INFO] Epoch: 150, Loss: 0.1301126480\n",
      "14:50:58.184 [INFO] Epoch: 160, Loss: 0.1265973300\n",
      "14:50:58.399 [INFO] Epoch: 170, Loss: 0.1191551089\n",
      "14:50:58.617 [INFO] Epoch: 180, Loss: 0.1213206798\n",
      "14:50:58.829 [INFO] Epoch: 190, Loss: 0.1257489771\n",
      "14:50:59.400 [INFO] Epoch: 200, Loss: 0.1166027337\n",
      "14:50:59.262 [INFO] Epoch: 210, Loss: 0.1191654950\n",
      "14:50:59.504 [INFO] Epoch: 220, Loss: 0.1217286289\n",
      "14:50:59.746 [INFO] Epoch: 230, Loss: 0.1235427782\n",
      "14:50:59.985 [INFO] Epoch: 240, Loss: 0.1246557608\n",
      "14:51:00.212 [INFO] Epoch: 250, Loss: 0.1197273359\n",
      "14:51:00.354 [INFO] Epoch: 256, Loss: 0.1235033423\n",
      "14:51:00.355 [INFO] Pruning weights (40 / 62)\n",
      "14:51:00.400 [INFO] Shed 0.045480791479349136 weight\n",
      "14:51:00.420 [INFO] Constructed symbolic model\n",
      "14:51:00.644 [INFO] Constructed loss equation\n",
      "14:51:01.350 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:02.962 [INFO] Epoch: 1, Loss: 0.1642753929\n",
      "14:51:03.179 [INFO] Epoch: 10, Loss: 0.1366261840\n",
      "14:51:03.402 [INFO] Epoch: 20, Loss: 0.1247347444\n",
      "14:51:03.628 [INFO] Epoch: 30, Loss: 0.1297040284\n",
      "14:51:03.856 [INFO] Epoch: 40, Loss: 0.1187497079\n",
      "14:51:04.800 [INFO] Epoch: 50, Loss: 0.1154453456\n",
      "14:51:04.319 [INFO] Epoch: 60, Loss: 0.1267106086\n",
      "14:51:04.536 [INFO] Epoch: 70, Loss: 0.1260464936\n",
      "14:51:04.759 [INFO] Epoch: 80, Loss: 0.1262318045\n",
      "14:51:04.997 [INFO] Epoch: 90, Loss: 0.1159823015\n",
      "14:51:05.234 [INFO] Epoch: 100, Loss: 0.1247878000\n",
      "14:51:05.475 [INFO] Epoch: 110, Loss: 0.1239517182\n",
      "14:51:05.714 [INFO] Epoch: 120, Loss: 0.1189297587\n",
      "14:51:05.976 [INFO] Epoch: 130, Loss: 0.1191410273\n",
      "14:51:06.206 [INFO] Epoch: 140, Loss: 0.1237964109\n",
      "14:51:06.432 [INFO] Epoch: 150, Loss: 0.1187735945\n",
      "14:51:06.675 [INFO] Epoch: 160, Loss: 0.1235981211\n",
      "14:51:06.912 [INFO] Epoch: 170, Loss: 0.1197331324\n",
      "14:51:07.132 [INFO] Epoch: 180, Loss: 0.1221664697\n",
      "14:51:07.357 [INFO] Epoch: 190, Loss: 0.1145998538\n",
      "14:51:07.591 [INFO] Epoch: 200, Loss: 0.1231919527\n",
      "14:51:07.830 [INFO] Epoch: 210, Loss: 0.1096024215\n",
      "14:51:08.530 [INFO] Epoch: 220, Loss: 0.1231060177\n",
      "14:51:08.281 [INFO] Epoch: 230, Loss: 0.1257710010\n",
      "14:51:08.504 [INFO] Epoch: 240, Loss: 0.1235411689\n",
      "14:51:08.747 [INFO] Epoch: 250, Loss: 0.1198272184\n",
      "14:51:08.882 [INFO] Epoch: 256, Loss: 0.1234658137\n",
      "14:51:08.883 [INFO] Pruning weights (41 / 62)\n",
      "14:51:08.927 [INFO] Shed 0.3896634578704834 weight\n",
      "14:51:08.945 [INFO] Constructed symbolic model\n",
      "14:51:09.158 [INFO] Constructed loss equation\n",
      "14:51:09.498 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:11.413 [INFO] Epoch: 1, Loss: 0.8454937935\n",
      "14:51:11.606 [INFO] Epoch: 10, Loss: 0.1717960238\n",
      "14:51:11.818 [INFO] Epoch: 20, Loss: 0.1590988934\n",
      "14:51:12.470 [INFO] Epoch: 30, Loss: 0.1403557658\n",
      "14:51:12.256 [INFO] Epoch: 40, Loss: 0.1315443516\n",
      "14:51:12.477 [INFO] Epoch: 50, Loss: 0.1362303048\n",
      "14:51:12.716 [INFO] Epoch: 60, Loss: 0.1251406968\n",
      "14:51:12.946 [INFO] Epoch: 70, Loss: 0.1401391327\n",
      "14:51:13.176 [INFO] Epoch: 80, Loss: 0.1209687218\n",
      "14:51:13.392 [INFO] Epoch: 90, Loss: 0.1262527406\n",
      "14:51:13.618 [INFO] Epoch: 100, Loss: 0.1293412894\n",
      "14:51:13.830 [INFO] Epoch: 110, Loss: 0.1340849847\n",
      "14:51:14.540 [INFO] Epoch: 120, Loss: 0.1276918501\n",
      "14:51:14.282 [INFO] Epoch: 130, Loss: 0.1385500878\n",
      "14:51:14.512 [INFO] Epoch: 140, Loss: 0.1287000179\n",
      "14:51:14.743 [INFO] Epoch: 150, Loss: 0.1249185950\n",
      "14:51:14.955 [INFO] Epoch: 160, Loss: 0.1183825880\n",
      "14:51:15.165 [INFO] Epoch: 170, Loss: 0.1275028288\n",
      "14:51:15.375 [INFO] Epoch: 180, Loss: 0.1239446774\n",
      "14:51:15.586 [INFO] Epoch: 190, Loss: 0.1202080846\n",
      "14:51:15.797 [INFO] Epoch: 200, Loss: 0.1288846731\n",
      "14:51:16.110 [INFO] Epoch: 210, Loss: 0.1135197282\n",
      "14:51:16.222 [INFO] Epoch: 220, Loss: 0.1184024960\n",
      "14:51:16.435 [INFO] Epoch: 230, Loss: 0.1248424053\n",
      "14:51:16.647 [INFO] Epoch: 240, Loss: 0.1215773672\n",
      "14:51:16.863 [INFO] Epoch: 250, Loss: 0.1231622919\n",
      "14:51:16.991 [INFO] Epoch: 256, Loss: 0.1277938038\n",
      "14:51:16.992 [INFO] Pruning weights (42 / 62)\n",
      "14:51:17.220 [INFO] Shed 0.0013089331332594156 weight\n",
      "14:51:17.410 [INFO] Constructed symbolic model\n",
      "14:51:17.285 [INFO] Constructed loss equation\n",
      "14:51:17.632 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:19.690 [INFO] Epoch: 1, Loss: 0.2799055874\n",
      "14:51:19.906 [INFO] Epoch: 10, Loss: 0.1335563958\n",
      "14:51:20.140 [INFO] Epoch: 20, Loss: 0.1308222860\n",
      "14:51:20.369 [INFO] Epoch: 30, Loss: 0.1309199482\n",
      "14:51:20.584 [INFO] Epoch: 40, Loss: 0.1454438865\n",
      "14:51:20.807 [INFO] Epoch: 50, Loss: 0.1275129020\n",
      "14:51:21.250 [INFO] Epoch: 60, Loss: 0.1292608976\n",
      "14:51:21.266 [INFO] Epoch: 70, Loss: 0.1388486326\n",
      "14:51:21.510 [INFO] Epoch: 80, Loss: 0.1120933369\n",
      "14:51:21.746 [INFO] Epoch: 90, Loss: 0.1279577762\n",
      "14:51:22.400 [INFO] Epoch: 100, Loss: 0.1282772124\n",
      "14:51:22.279 [INFO] Epoch: 110, Loss: 0.1194593832\n",
      "14:51:22.511 [INFO] Epoch: 120, Loss: 0.1258150339\n",
      "14:51:22.736 [INFO] Epoch: 130, Loss: 0.1184217483\n",
      "14:51:22.978 [INFO] Epoch: 140, Loss: 0.1219704747\n",
      "14:51:23.207 [INFO] Epoch: 150, Loss: 0.1301987022\n",
      "14:51:23.440 [INFO] Epoch: 160, Loss: 0.1247310191\n",
      "14:51:23.672 [INFO] Epoch: 170, Loss: 0.1345588863\n",
      "14:51:23.908 [INFO] Epoch: 180, Loss: 0.1299544573\n",
      "14:51:24.129 [INFO] Epoch: 190, Loss: 0.1243979782\n",
      "14:51:24.343 [INFO] Epoch: 200, Loss: 0.1362450719\n",
      "14:51:24.566 [INFO] Epoch: 210, Loss: 0.1250195801\n",
      "14:51:24.801 [INFO] Epoch: 220, Loss: 0.1265221536\n",
      "14:51:25.500 [INFO] Epoch: 230, Loss: 0.1226669997\n",
      "14:51:25.286 [INFO] Epoch: 240, Loss: 0.1189378425\n",
      "14:51:25.520 [INFO] Epoch: 250, Loss: 0.1281043589\n",
      "14:51:25.657 [INFO] Epoch: 256, Loss: 0.1279969215\n",
      "14:51:25.658 [INFO] Pruning weights (43 / 62)\n",
      "14:51:25.703 [INFO] Shed 0.0013416369911283255 weight\n",
      "14:51:25.750 [INFO] Constructed symbolic model\n",
      "14:51:25.973 [INFO] Constructed loss equation\n",
      "14:51:26.283 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:28.720 [INFO] Epoch: 1, Loss: 0.3977473974\n",
      "14:51:28.283 [INFO] Epoch: 10, Loss: 0.1299519986\n",
      "14:51:28.506 [INFO] Epoch: 20, Loss: 0.1403143704\n",
      "14:51:28.728 [INFO] Epoch: 30, Loss: 0.1373859644\n",
      "14:51:28.941 [INFO] Epoch: 40, Loss: 0.1329046488\n",
      "14:51:29.154 [INFO] Epoch: 50, Loss: 0.1253759414\n",
      "14:51:29.366 [INFO] Epoch: 60, Loss: 0.1236670166\n",
      "14:51:29.581 [INFO] Epoch: 70, Loss: 0.1274653524\n",
      "14:51:29.795 [INFO] Epoch: 80, Loss: 0.1257329583\n",
      "14:51:30.160 [INFO] Epoch: 90, Loss: 0.1237657219\n",
      "14:51:30.240 [INFO] Epoch: 100, Loss: 0.1364640892\n",
      "14:51:30.473 [INFO] Epoch: 110, Loss: 0.1284772158\n",
      "14:51:30.698 [INFO] Epoch: 120, Loss: 0.1279258132\n",
      "14:51:30.925 [INFO] Epoch: 130, Loss: 0.1264517009\n",
      "14:51:31.136 [INFO] Epoch: 140, Loss: 0.1279169321\n",
      "14:51:31.364 [INFO] Epoch: 150, Loss: 0.1251697242\n",
      "14:51:31.591 [INFO] Epoch: 160, Loss: 0.1267491430\n",
      "14:51:31.803 [INFO] Epoch: 170, Loss: 0.1198339611\n",
      "14:51:32.130 [INFO] Epoch: 180, Loss: 0.1271222681\n",
      "14:51:32.224 [INFO] Epoch: 190, Loss: 0.1299899071\n",
      "14:51:32.438 [INFO] Epoch: 200, Loss: 0.1306189001\n",
      "14:51:32.650 [INFO] Epoch: 210, Loss: 0.1284215748\n",
      "14:51:32.869 [INFO] Epoch: 220, Loss: 0.1238400042\n",
      "14:51:33.850 [INFO] Epoch: 230, Loss: 0.1196710542\n",
      "14:51:33.310 [INFO] Epoch: 240, Loss: 0.1217050925\n",
      "14:51:33.527 [INFO] Epoch: 250, Loss: 0.1242976263\n",
      "14:51:33.668 [INFO] Epoch: 256, Loss: 0.1218648851\n",
      "14:51:33.669 [INFO] Pruning weights (44 / 62)\n",
      "14:51:33.715 [INFO] Shed 0.008179494179785252 weight\n",
      "14:51:33.770 [INFO] Constructed symbolic model\n",
      "14:51:33.956 [INFO] Constructed loss equation\n",
      "14:51:34.218 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:35.864 [INFO] Epoch: 1, Loss: 0.3101299405\n",
      "14:51:36.640 [INFO] Epoch: 10, Loss: 0.1261579990\n",
      "14:51:36.274 [INFO] Epoch: 20, Loss: 0.1390363127\n",
      "14:51:36.488 [INFO] Epoch: 30, Loss: 0.1323106289\n",
      "14:51:36.701 [INFO] Epoch: 40, Loss: 0.1299950331\n",
      "14:51:36.914 [INFO] Epoch: 50, Loss: 0.1184408590\n",
      "14:51:37.129 [INFO] Epoch: 60, Loss: 0.1256363392\n",
      "14:51:37.344 [INFO] Epoch: 70, Loss: 0.1209538504\n",
      "14:51:37.562 [INFO] Epoch: 80, Loss: 0.1204357892\n",
      "14:51:37.781 [INFO] Epoch: 90, Loss: 0.1246953011\n",
      "14:51:37.1000 [INFO] Epoch: 100, Loss: 0.1249983981\n",
      "14:51:38.216 [INFO] Epoch: 110, Loss: 0.1244381592\n",
      "14:51:38.435 [INFO] Epoch: 120, Loss: 0.1249277145\n",
      "14:51:38.645 [INFO] Epoch: 130, Loss: 0.1142979115\n",
      "14:51:38.860 [INFO] Epoch: 140, Loss: 0.1255050898\n",
      "14:51:39.700 [INFO] Epoch: 150, Loss: 0.1301738620\n",
      "14:51:39.279 [INFO] Epoch: 160, Loss: 0.1210380122\n",
      "14:51:39.504 [INFO] Epoch: 170, Loss: 0.1227893755\n",
      "14:51:39.731 [INFO] Epoch: 180, Loss: 0.1219079271\n",
      "14:51:39.971 [INFO] Epoch: 190, Loss: 0.1206887364\n",
      "14:51:40.205 [INFO] Epoch: 200, Loss: 0.1261892617\n",
      "14:51:40.440 [INFO] Epoch: 210, Loss: 0.1188518777\n",
      "14:51:40.658 [INFO] Epoch: 220, Loss: 0.1400209367\n",
      "14:51:40.873 [INFO] Epoch: 230, Loss: 0.1242545992\n",
      "14:51:41.950 [INFO] Epoch: 240, Loss: 0.1213569343\n",
      "14:51:41.320 [INFO] Epoch: 250, Loss: 0.1276529431\n",
      "14:51:41.460 [INFO] Epoch: 256, Loss: 0.1271797270\n",
      "14:51:41.461 [INFO] Pruning weights (45 / 62)\n",
      "14:51:41.507 [INFO] Shed 0.010502091608941555 weight\n",
      "14:51:41.550 [INFO] Constructed symbolic model\n",
      "14:51:41.735 [INFO] Constructed loss equation\n",
      "14:51:42.110 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:43.716 [INFO] Epoch: 1, Loss: 0.2942740321\n",
      "14:51:43.917 [INFO] Epoch: 10, Loss: 0.1305711269\n",
      "14:51:44.126 [INFO] Epoch: 20, Loss: 0.1535350680\n",
      "14:51:44.330 [INFO] Epoch: 30, Loss: 0.1172436699\n",
      "14:51:44.534 [INFO] Epoch: 40, Loss: 0.1278507560\n",
      "14:51:44.776 [INFO] Epoch: 50, Loss: 0.1332983971\n",
      "14:51:44.996 [INFO] Epoch: 60, Loss: 0.1274182349\n",
      "14:51:45.211 [INFO] Epoch: 70, Loss: 0.1258035898\n",
      "14:51:45.420 [INFO] Epoch: 80, Loss: 0.1266404837\n",
      "14:51:45.629 [INFO] Epoch: 90, Loss: 0.1246963292\n",
      "14:51:45.839 [INFO] Epoch: 100, Loss: 0.1226555035\n",
      "14:51:46.470 [INFO] Epoch: 110, Loss: 0.1230783239\n",
      "14:51:46.253 [INFO] Epoch: 120, Loss: 0.1268965900\n",
      "14:51:46.459 [INFO] Epoch: 130, Loss: 0.1347441375\n",
      "14:51:46.668 [INFO] Epoch: 140, Loss: 0.1270372123\n",
      "14:51:46.877 [INFO] Epoch: 150, Loss: 0.1225022599\n",
      "14:51:47.860 [INFO] Epoch: 160, Loss: 0.1284370422\n",
      "14:51:47.295 [INFO] Epoch: 170, Loss: 0.1295153201\n",
      "14:51:47.501 [INFO] Epoch: 180, Loss: 0.1221008226\n",
      "14:51:47.709 [INFO] Epoch: 190, Loss: 0.1222092137\n",
      "14:51:47.917 [INFO] Epoch: 200, Loss: 0.1284179538\n",
      "14:51:48.129 [INFO] Epoch: 210, Loss: 0.1192302555\n",
      "14:51:48.346 [INFO] Epoch: 220, Loss: 0.1329467446\n",
      "14:51:48.580 [INFO] Epoch: 230, Loss: 0.1169080138\n",
      "14:51:48.810 [INFO] Epoch: 240, Loss: 0.1198702008\n",
      "14:51:49.150 [INFO] Epoch: 250, Loss: 0.1213411540\n",
      "14:51:49.150 [INFO] Epoch: 256, Loss: 0.1255819350\n",
      "14:51:49.151 [INFO] Pruning weights (46 / 62)\n",
      "14:51:49.194 [INFO] Shed 0.010987198911607265 weight\n",
      "14:51:49.210 [INFO] Constructed symbolic model\n",
      "14:51:49.365 [INFO] Constructed loss equation\n",
      "14:51:49.545 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:50.794 [INFO] Epoch: 1, Loss: 0.2153198272\n",
      "14:51:50.981 [INFO] Epoch: 10, Loss: 0.1331011206\n",
      "14:51:51.188 [INFO] Epoch: 20, Loss: 0.1224412024\n",
      "14:51:51.393 [INFO] Epoch: 30, Loss: 0.1305310428\n",
      "14:51:51.596 [INFO] Epoch: 40, Loss: 0.1316213906\n",
      "14:51:51.800 [INFO] Epoch: 50, Loss: 0.1397596151\n",
      "14:51:52.800 [INFO] Epoch: 60, Loss: 0.1178605855\n",
      "14:51:52.271 [INFO] Epoch: 70, Loss: 0.1215196773\n",
      "14:51:52.488 [INFO] Epoch: 80, Loss: 0.1292280406\n",
      "14:51:52.709 [INFO] Epoch: 90, Loss: 0.1213124841\n",
      "14:51:52.930 [INFO] Epoch: 100, Loss: 0.1265691966\n",
      "14:51:53.151 [INFO] Epoch: 110, Loss: 0.1263262630\n",
      "14:51:53.371 [INFO] Epoch: 120, Loss: 0.1226840317\n",
      "14:51:53.592 [INFO] Epoch: 130, Loss: 0.1251357943\n",
      "14:51:53.814 [INFO] Epoch: 140, Loss: 0.1319156587\n",
      "14:51:54.420 [INFO] Epoch: 150, Loss: 0.1188212335\n",
      "14:51:54.266 [INFO] Epoch: 160, Loss: 0.1240987778\n",
      "14:51:54.498 [INFO] Epoch: 170, Loss: 0.1190054715\n",
      "14:51:54.721 [INFO] Epoch: 180, Loss: 0.1246234030\n",
      "14:51:54.962 [INFO] Epoch: 190, Loss: 0.1220830530\n",
      "14:51:55.204 [INFO] Epoch: 200, Loss: 0.1244454831\n",
      "14:51:55.432 [INFO] Epoch: 210, Loss: 0.1239032000\n",
      "14:51:55.669 [INFO] Epoch: 220, Loss: 0.1232038438\n",
      "14:51:55.913 [INFO] Epoch: 230, Loss: 0.1201134771\n",
      "14:51:56.145 [INFO] Epoch: 240, Loss: 0.1194985807\n",
      "14:51:56.370 [INFO] Epoch: 250, Loss: 0.1220473796\n",
      "14:51:56.508 [INFO] Epoch: 256, Loss: 0.1263106912\n",
      "14:51:56.509 [INFO] Pruning weights (47 / 62)\n",
      "14:51:56.556 [INFO] Shed 0.011437367647886276 weight\n",
      "14:51:56.568 [INFO] Constructed symbolic model\n",
      "14:51:56.646 [INFO] Constructed loss equation\n",
      "14:51:56.754 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:51:58.125 [INFO] Epoch: 1, Loss: 0.4020283818\n",
      "14:51:58.329 [INFO] Epoch: 10, Loss: 0.1209921390\n",
      "14:51:58.535 [INFO] Epoch: 20, Loss: 0.1384085566\n",
      "14:51:58.740 [INFO] Epoch: 30, Loss: 0.1185121536\n",
      "14:51:58.948 [INFO] Epoch: 40, Loss: 0.1249755025\n",
      "14:51:59.160 [INFO] Epoch: 50, Loss: 0.1220548600\n",
      "14:51:59.386 [INFO] Epoch: 60, Loss: 0.1322720945\n",
      "14:51:59.616 [INFO] Epoch: 70, Loss: 0.1208611056\n",
      "14:51:59.837 [INFO] Epoch: 80, Loss: 0.1303583682\n",
      "14:52:00.750 [INFO] Epoch: 90, Loss: 0.1247746274\n",
      "14:52:00.307 [INFO] Epoch: 100, Loss: 0.1340420246\n",
      "14:52:00.529 [INFO] Epoch: 110, Loss: 0.1206947416\n",
      "14:52:00.751 [INFO] Epoch: 120, Loss: 0.1186228991\n",
      "14:52:00.973 [INFO] Epoch: 130, Loss: 0.1241009831\n",
      "14:52:01.196 [INFO] Epoch: 140, Loss: 0.1238898486\n",
      "14:52:01.423 [INFO] Epoch: 150, Loss: 0.1252119392\n",
      "14:52:01.653 [INFO] Epoch: 160, Loss: 0.1343330145\n",
      "14:52:01.893 [INFO] Epoch: 170, Loss: 0.1230081618\n",
      "14:52:02.121 [INFO] Epoch: 180, Loss: 0.1210959852\n",
      "14:52:02.344 [INFO] Epoch: 190, Loss: 0.1211704984\n",
      "14:52:02.563 [INFO] Epoch: 200, Loss: 0.1187715605\n",
      "14:52:02.784 [INFO] Epoch: 210, Loss: 0.1316414773\n",
      "14:52:03.600 [INFO] Epoch: 220, Loss: 0.1190271080\n",
      "14:52:03.234 [INFO] Epoch: 230, Loss: 0.1191327348\n",
      "14:52:03.452 [INFO] Epoch: 240, Loss: 0.1265745163\n",
      "14:52:03.704 [INFO] Epoch: 250, Loss: 0.1202962101\n",
      "14:52:03.848 [INFO] Epoch: 256, Loss: 0.1204013601\n",
      "14:52:03.849 [INFO] Pruning weights (48 / 62)\n",
      "14:52:03.894 [INFO] Shed 0.12140470743179321 weight\n",
      "14:52:03.909 [INFO] Constructed symbolic model\n",
      "14:52:04.260 [INFO] Constructed loss equation\n",
      "14:52:04.182 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:05.508 [INFO] Epoch: 1, Loss: 0.2867399454\n",
      "14:52:05.710 [INFO] Epoch: 10, Loss: 0.1682848930\n",
      "14:52:05.936 [INFO] Epoch: 20, Loss: 0.1262018830\n",
      "14:52:06.134 [INFO] Epoch: 30, Loss: 0.1290494651\n",
      "14:52:06.343 [INFO] Epoch: 40, Loss: 0.1423794478\n",
      "14:52:06.562 [INFO] Epoch: 50, Loss: 0.1261032522\n",
      "14:52:06.780 [INFO] Epoch: 60, Loss: 0.1410031319\n",
      "14:52:06.998 [INFO] Epoch: 70, Loss: 0.1317323148\n",
      "14:52:07.225 [INFO] Epoch: 80, Loss: 0.1312177479\n",
      "14:52:07.440 [INFO] Epoch: 90, Loss: 0.1247678250\n",
      "14:52:07.654 [INFO] Epoch: 100, Loss: 0.1296847761\n",
      "14:52:07.869 [INFO] Epoch: 110, Loss: 0.1434597075\n",
      "14:52:08.880 [INFO] Epoch: 120, Loss: 0.1263682246\n",
      "14:52:08.304 [INFO] Epoch: 130, Loss: 0.1237213239\n",
      "14:52:08.538 [INFO] Epoch: 140, Loss: 0.1227397770\n",
      "14:52:08.781 [INFO] Epoch: 150, Loss: 0.1332108676\n",
      "14:52:09.100 [INFO] Epoch: 160, Loss: 0.1228217781\n",
      "14:52:09.256 [INFO] Epoch: 170, Loss: 0.1190115139\n",
      "14:52:09.491 [INFO] Epoch: 180, Loss: 0.1214678660\n",
      "14:52:09.726 [INFO] Epoch: 190, Loss: 0.1244370416\n",
      "14:52:09.958 [INFO] Epoch: 200, Loss: 0.1280597299\n",
      "14:52:10.180 [INFO] Epoch: 210, Loss: 0.1287278086\n",
      "14:52:10.427 [INFO] Epoch: 220, Loss: 0.1218623072\n",
      "14:52:10.653 [INFO] Epoch: 230, Loss: 0.1232372522\n",
      "14:52:10.878 [INFO] Epoch: 240, Loss: 0.1245857179\n",
      "14:52:11.105 [INFO] Epoch: 250, Loss: 0.1216274425\n",
      "14:52:11.238 [INFO] Epoch: 256, Loss: 0.1206002533\n",
      "14:52:11.238 [INFO] Pruning weights (49 / 62)\n",
      "14:52:11.274 [INFO] Shed 0.00011993572843493894 weight\n",
      "14:52:11.292 [INFO] Constructed symbolic model\n",
      "14:52:11.358 [INFO] Constructed loss equation\n",
      "14:52:11.494 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:13.800 [INFO] Epoch: 1, Loss: 0.2305486202\n",
      "14:52:13.208 [INFO] Epoch: 10, Loss: 0.1316423118\n",
      "14:52:13.426 [INFO] Epoch: 20, Loss: 0.1325666159\n",
      "14:52:13.644 [INFO] Epoch: 30, Loss: 0.1351927519\n",
      "14:52:13.867 [INFO] Epoch: 40, Loss: 0.1349046528\n",
      "14:52:14.890 [INFO] Epoch: 50, Loss: 0.1272869259\n",
      "14:52:14.313 [INFO] Epoch: 60, Loss: 0.1250658333\n",
      "14:52:14.540 [INFO] Epoch: 70, Loss: 0.1340822577\n",
      "14:52:14.761 [INFO] Epoch: 80, Loss: 0.1298437119\n",
      "14:52:14.979 [INFO] Epoch: 90, Loss: 0.1243151128\n",
      "14:52:15.198 [INFO] Epoch: 100, Loss: 0.1183127835\n",
      "14:52:15.417 [INFO] Epoch: 110, Loss: 0.1260800958\n",
      "14:52:15.643 [INFO] Epoch: 120, Loss: 0.1313094944\n",
      "14:52:15.878 [INFO] Epoch: 130, Loss: 0.1277291179\n",
      "14:52:16.109 [INFO] Epoch: 140, Loss: 0.1343009472\n",
      "14:52:16.333 [INFO] Epoch: 150, Loss: 0.1244327202\n",
      "14:52:16.575 [INFO] Epoch: 160, Loss: 0.1183863580\n",
      "14:52:16.820 [INFO] Epoch: 170, Loss: 0.1275821030\n",
      "14:52:17.490 [INFO] Epoch: 180, Loss: 0.1311983615\n",
      "14:52:17.298 [INFO] Epoch: 190, Loss: 0.1198053956\n",
      "14:52:17.522 [INFO] Epoch: 200, Loss: 0.1253894866\n",
      "14:52:17.743 [INFO] Epoch: 210, Loss: 0.1220349520\n",
      "14:52:17.961 [INFO] Epoch: 220, Loss: 0.1312701106\n",
      "14:52:18.182 [INFO] Epoch: 230, Loss: 0.1204123795\n",
      "14:52:18.404 [INFO] Epoch: 240, Loss: 0.1287303865\n",
      "14:52:18.621 [INFO] Epoch: 250, Loss: 0.1236716360\n",
      "14:52:18.769 [INFO] Epoch: 256, Loss: 0.1202619076\n",
      "14:52:18.770 [INFO] Pruning weights (50 / 62)\n",
      "14:52:18.821 [INFO] Shed 0.01770261488854885 weight\n",
      "14:52:18.831 [INFO] Constructed symbolic model\n",
      "14:52:18.892 [INFO] Constructed loss equation\n",
      "14:52:19.220 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:20.250 [INFO] Epoch: 1, Loss: 0.2710389495\n",
      "14:52:20.481 [INFO] Epoch: 10, Loss: 0.1235315278\n",
      "14:52:20.707 [INFO] Epoch: 20, Loss: 0.1510528624\n",
      "14:52:20.917 [INFO] Epoch: 30, Loss: 0.1283881664\n",
      "14:52:21.165 [INFO] Epoch: 40, Loss: 0.1240877509\n",
      "14:52:21.386 [INFO] Epoch: 50, Loss: 0.1286758780\n",
      "14:52:21.604 [INFO] Epoch: 60, Loss: 0.1337864995\n",
      "14:52:21.820 [INFO] Epoch: 70, Loss: 0.1285483688\n",
      "14:52:22.340 [INFO] Epoch: 80, Loss: 0.1338768601\n",
      "14:52:22.251 [INFO] Epoch: 90, Loss: 0.1393128484\n",
      "14:52:22.464 [INFO] Epoch: 100, Loss: 0.1268664896\n",
      "14:52:22.680 [INFO] Epoch: 110, Loss: 0.1350734532\n",
      "14:52:22.897 [INFO] Epoch: 120, Loss: 0.1386003047\n",
      "14:52:23.113 [INFO] Epoch: 130, Loss: 0.1193794534\n",
      "14:52:23.330 [INFO] Epoch: 140, Loss: 0.1337475628\n",
      "14:52:23.562 [INFO] Epoch: 150, Loss: 0.1297921091\n",
      "14:52:23.813 [INFO] Epoch: 160, Loss: 0.1327747554\n",
      "14:52:24.870 [INFO] Epoch: 170, Loss: 0.1260851324\n",
      "14:52:24.318 [INFO] Epoch: 180, Loss: 0.1285509616\n",
      "14:52:24.552 [INFO] Epoch: 190, Loss: 0.1193328053\n",
      "14:52:24.782 [INFO] Epoch: 200, Loss: 0.1253261417\n",
      "14:52:24.997 [INFO] Epoch: 210, Loss: 0.1287444681\n",
      "14:52:25.216 [INFO] Epoch: 220, Loss: 0.1217583269\n",
      "14:52:25.425 [INFO] Epoch: 230, Loss: 0.1317618489\n",
      "14:52:25.644 [INFO] Epoch: 240, Loss: 0.1315860003\n",
      "14:52:25.863 [INFO] Epoch: 250, Loss: 0.1227108389\n",
      "14:52:25.993 [INFO] Epoch: 256, Loss: 0.1258760095\n",
      "14:52:25.994 [INFO] Pruning weights (51 / 62)\n",
      "14:52:26.400 [INFO] Shed 0.03842565044760704 weight\n",
      "14:52:26.480 [INFO] Constructed symbolic model\n",
      "14:52:26.110 [INFO] Constructed loss equation\n",
      "14:52:26.237 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:27.313 [INFO] Epoch: 1, Loss: 0.3168213367\n",
      "14:52:27.517 [INFO] Epoch: 10, Loss: 0.1223677471\n",
      "14:52:27.744 [INFO] Epoch: 20, Loss: 0.1401314884\n",
      "14:52:27.957 [INFO] Epoch: 30, Loss: 0.1383332312\n",
      "14:52:28.183 [INFO] Epoch: 40, Loss: 0.1373921037\n",
      "14:52:28.401 [INFO] Epoch: 50, Loss: 0.1331416219\n",
      "14:52:28.617 [INFO] Epoch: 60, Loss: 0.1253488660\n",
      "14:52:28.831 [INFO] Epoch: 70, Loss: 0.1223040074\n",
      "14:52:29.540 [INFO] Epoch: 80, Loss: 0.1258580387\n",
      "14:52:29.289 [INFO] Epoch: 90, Loss: 0.1199075058\n",
      "14:52:29.510 [INFO] Epoch: 100, Loss: 0.1231316477\n",
      "14:52:29.736 [INFO] Epoch: 110, Loss: 0.1322750151\n",
      "14:52:29.949 [INFO] Epoch: 120, Loss: 0.1277940869\n",
      "14:52:30.168 [INFO] Epoch: 130, Loss: 0.1262810826\n",
      "14:52:30.387 [INFO] Epoch: 140, Loss: 0.1334785521\n",
      "14:52:30.602 [INFO] Epoch: 150, Loss: 0.1304619908\n",
      "14:52:30.826 [INFO] Epoch: 160, Loss: 0.1304325312\n",
      "14:52:31.610 [INFO] Epoch: 170, Loss: 0.1224605590\n",
      "14:52:31.294 [INFO] Epoch: 180, Loss: 0.1245834678\n",
      "14:52:31.516 [INFO] Epoch: 190, Loss: 0.1205766201\n",
      "14:52:31.753 [INFO] Epoch: 200, Loss: 0.1243904829\n",
      "14:52:31.978 [INFO] Epoch: 210, Loss: 0.1315542608\n",
      "14:52:32.181 [INFO] Epoch: 220, Loss: 0.1240308806\n",
      "14:52:32.389 [INFO] Epoch: 230, Loss: 0.1153275967\n",
      "14:52:32.610 [INFO] Epoch: 240, Loss: 0.1178917438\n",
      "14:52:32.829 [INFO] Epoch: 250, Loss: 0.1258497536\n",
      "14:52:32.956 [INFO] Epoch: 256, Loss: 0.1275488734\n",
      "14:52:32.956 [INFO] Pruning weights (52 / 62)\n",
      "14:52:33.700 [INFO] Shed 0.0625363141298294 weight\n",
      "14:52:33.150 [INFO] Constructed symbolic model\n",
      "14:52:33.700 [INFO] Constructed loss equation\n",
      "14:52:33.228 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:34.552 [INFO] Epoch: 1, Loss: 0.2467612624\n",
      "14:52:34.773 [INFO] Epoch: 10, Loss: 0.1461490840\n",
      "14:52:35.160 [INFO] Epoch: 20, Loss: 0.1240535453\n",
      "14:52:35.269 [INFO] Epoch: 30, Loss: 0.1235801876\n",
      "14:52:35.511 [INFO] Epoch: 40, Loss: 0.1283012331\n",
      "14:52:35.785 [INFO] Epoch: 50, Loss: 0.1419988275\n",
      "14:52:36.100 [INFO] Epoch: 60, Loss: 0.1263720989\n",
      "14:52:36.227 [INFO] Epoch: 70, Loss: 0.1271657944\n",
      "14:52:36.450 [INFO] Epoch: 80, Loss: 0.1330620348\n",
      "14:52:36.662 [INFO] Epoch: 90, Loss: 0.1263808608\n",
      "14:52:36.889 [INFO] Epoch: 100, Loss: 0.1200542375\n",
      "14:52:37.112 [INFO] Epoch: 110, Loss: 0.1234579533\n",
      "14:52:37.326 [INFO] Epoch: 120, Loss: 0.1172114909\n",
      "14:52:37.539 [INFO] Epoch: 130, Loss: 0.1221544445\n",
      "14:52:37.751 [INFO] Epoch: 140, Loss: 0.1271872371\n",
      "14:52:37.967 [INFO] Epoch: 150, Loss: 0.1320691556\n",
      "14:52:38.199 [INFO] Epoch: 160, Loss: 0.1239020303\n",
      "14:52:38.408 [INFO] Epoch: 170, Loss: 0.1240744218\n",
      "14:52:38.621 [INFO] Epoch: 180, Loss: 0.1270965040\n",
      "14:52:38.868 [INFO] Epoch: 190, Loss: 0.1252195537\n",
      "14:52:39.850 [INFO] Epoch: 200, Loss: 0.1269774735\n",
      "14:52:39.304 [INFO] Epoch: 210, Loss: 0.1238653734\n",
      "14:52:39.509 [INFO] Epoch: 220, Loss: 0.1178793162\n",
      "14:52:39.734 [INFO] Epoch: 230, Loss: 0.1316834390\n",
      "14:52:39.951 [INFO] Epoch: 240, Loss: 0.1212478280\n",
      "14:52:40.157 [INFO] Epoch: 250, Loss: 0.1194142997\n",
      "14:52:40.282 [INFO] Epoch: 256, Loss: 0.1250465512\n",
      "14:52:40.282 [INFO] Pruning weights (53 / 62)\n",
      "14:52:40.330 [INFO] Shed 0.07755565643310547 weight\n",
      "14:52:40.338 [INFO] Constructed symbolic model\n",
      "14:52:40.373 [INFO] Constructed loss equation\n",
      "14:52:40.466 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:41.466 [INFO] Epoch: 1, Loss: 0.2823423743\n",
      "14:52:41.655 [INFO] Epoch: 10, Loss: 0.1440174878\n",
      "14:52:41.863 [INFO] Epoch: 20, Loss: 0.1284278333\n",
      "14:52:42.720 [INFO] Epoch: 30, Loss: 0.1292058825\n",
      "14:52:42.289 [INFO] Epoch: 40, Loss: 0.1324641705\n",
      "14:52:42.505 [INFO] Epoch: 50, Loss: 0.1278093755\n",
      "14:52:42.722 [INFO] Epoch: 60, Loss: 0.1355158836\n",
      "14:52:42.939 [INFO] Epoch: 70, Loss: 0.1254687160\n",
      "14:52:43.169 [INFO] Epoch: 80, Loss: 0.1286861449\n",
      "14:52:43.398 [INFO] Epoch: 90, Loss: 0.1282432973\n",
      "14:52:43.630 [INFO] Epoch: 100, Loss: 0.1283832490\n",
      "14:52:43.863 [INFO] Epoch: 110, Loss: 0.1301599443\n",
      "14:52:44.850 [INFO] Epoch: 120, Loss: 0.1122748107\n",
      "14:52:44.317 [INFO] Epoch: 130, Loss: 0.1277553737\n",
      "14:52:44.582 [INFO] Epoch: 140, Loss: 0.1336618364\n",
      "14:52:44.801 [INFO] Epoch: 150, Loss: 0.1255138516\n",
      "14:52:45.300 [INFO] Epoch: 160, Loss: 0.1293706298\n",
      "14:52:45.259 [INFO] Epoch: 170, Loss: 0.1226850823\n",
      "14:52:45.482 [INFO] Epoch: 180, Loss: 0.1308877468\n",
      "14:52:45.709 [INFO] Epoch: 190, Loss: 0.1229315400\n",
      "14:52:45.940 [INFO] Epoch: 200, Loss: 0.1238617823\n",
      "14:52:46.164 [INFO] Epoch: 210, Loss: 0.1325115710\n",
      "14:52:46.399 [INFO] Epoch: 220, Loss: 0.1278645396\n",
      "14:52:46.652 [INFO] Epoch: 230, Loss: 0.1244303286\n",
      "14:52:46.893 [INFO] Epoch: 240, Loss: 0.1227142364\n",
      "14:52:47.118 [INFO] Epoch: 250, Loss: 0.1257460713\n",
      "14:52:47.256 [INFO] Epoch: 256, Loss: 0.1232834011\n",
      "14:52:47.257 [INFO] Pruning weights (54 / 62)\n",
      "14:52:47.306 [INFO] Shed 0.1456337869167328 weight\n",
      "14:52:47.313 [INFO] Constructed symbolic model\n",
      "14:52:47.356 [INFO] Constructed loss equation\n",
      "14:52:47.447 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:48.552 [INFO] Epoch: 1, Loss: 0.2554928362\n",
      "14:52:48.753 [INFO] Epoch: 10, Loss: 0.1343438029\n",
      "14:52:48.975 [INFO] Epoch: 20, Loss: 0.1373089850\n",
      "14:52:49.193 [INFO] Epoch: 30, Loss: 0.1236779392\n",
      "14:52:49.433 [INFO] Epoch: 40, Loss: 0.1268405169\n",
      "14:52:49.711 [INFO] Epoch: 50, Loss: 0.1479872167\n",
      "14:52:49.977 [INFO] Epoch: 60, Loss: 0.1497254968\n",
      "14:52:50.224 [INFO] Epoch: 70, Loss: 0.1252162755\n",
      "14:52:50.477 [INFO] Epoch: 80, Loss: 0.1295436323\n",
      "14:52:50.705 [INFO] Epoch: 90, Loss: 0.1278285682\n",
      "14:52:50.922 [INFO] Epoch: 100, Loss: 0.1304902434\n",
      "14:52:51.133 [INFO] Epoch: 110, Loss: 0.1213070899\n",
      "14:52:51.340 [INFO] Epoch: 120, Loss: 0.1238615215\n",
      "14:52:51.552 [INFO] Epoch: 130, Loss: 0.1272462308\n",
      "14:52:51.779 [INFO] Epoch: 140, Loss: 0.1270917505\n",
      "14:52:52.900 [INFO] Epoch: 150, Loss: 0.1303473562\n",
      "14:52:52.228 [INFO] Epoch: 160, Loss: 0.1263478696\n",
      "14:52:52.443 [INFO] Epoch: 170, Loss: 0.1142094806\n",
      "14:52:52.648 [INFO] Epoch: 180, Loss: 0.1283895075\n",
      "14:52:52.861 [INFO] Epoch: 190, Loss: 0.1242352426\n",
      "14:52:53.730 [INFO] Epoch: 200, Loss: 0.1241110638\n",
      "14:52:53.290 [INFO] Epoch: 210, Loss: 0.1237313896\n",
      "14:52:53.488 [INFO] Epoch: 220, Loss: 0.1237728149\n",
      "14:52:53.705 [INFO] Epoch: 230, Loss: 0.1264155507\n",
      "14:52:53.954 [INFO] Epoch: 240, Loss: 0.1243379116\n",
      "14:52:54.178 [INFO] Epoch: 250, Loss: 0.1241915077\n",
      "14:52:54.313 [INFO] Epoch: 256, Loss: 0.1219835877\n",
      "14:52:54.314 [INFO] Pruning weights (55 / 62)\n",
      "14:52:54.366 [INFO] Shed 0.2791288495063782 weight\n",
      "14:52:54.373 [INFO] Constructed symbolic model\n",
      "14:52:54.453 [INFO] Constructed loss equation\n",
      "14:52:54.598 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:52:55.933 [INFO] Epoch: 1, Loss: 0.7434481978\n",
      "14:52:56.135 [INFO] Epoch: 10, Loss: 0.1995346248\n",
      "14:52:56.360 [INFO] Epoch: 20, Loss: 0.1583836377\n",
      "14:52:56.576 [INFO] Epoch: 30, Loss: 0.1520735025\n",
      "14:52:56.792 [INFO] Epoch: 40, Loss: 0.1395850480\n",
      "14:52:56.994 [INFO] Epoch: 50, Loss: 0.1410004497\n",
      "14:52:57.196 [INFO] Epoch: 60, Loss: 0.1496869326\n",
      "14:52:57.399 [INFO] Epoch: 70, Loss: 0.1469128579\n",
      "14:52:57.599 [INFO] Epoch: 80, Loss: 0.1347858310\n",
      "14:52:57.799 [INFO] Epoch: 90, Loss: 0.1384094059\n",
      "14:52:57.997 [INFO] Epoch: 100, Loss: 0.1376594007\n",
      "14:52:58.195 [INFO] Epoch: 110, Loss: 0.1383918822\n",
      "14:52:58.394 [INFO] Epoch: 120, Loss: 0.1333214641\n",
      "14:52:58.593 [INFO] Epoch: 130, Loss: 0.1345779300\n",
      "14:52:58.797 [INFO] Epoch: 140, Loss: 0.1301614940\n",
      "14:52:59.500 [INFO] Epoch: 150, Loss: 0.1332164407\n",
      "14:52:59.221 [INFO] Epoch: 160, Loss: 0.1399869919\n",
      "14:52:59.434 [INFO] Epoch: 170, Loss: 0.1372269690\n",
      "14:52:59.644 [INFO] Epoch: 180, Loss: 0.1412751377\n",
      "14:52:59.855 [INFO] Epoch: 190, Loss: 0.1313607693\n",
      "14:53:00.670 [INFO] Epoch: 200, Loss: 0.1410168111\n",
      "14:53:00.278 [INFO] Epoch: 210, Loss: 0.1407325566\n",
      "14:53:00.487 [INFO] Epoch: 220, Loss: 0.1428505480\n",
      "14:53:00.696 [INFO] Epoch: 230, Loss: 0.1441721618\n",
      "14:53:00.906 [INFO] Epoch: 240, Loss: 0.1301647872\n",
      "14:53:01.113 [INFO] Epoch: 250, Loss: 0.1354354322\n",
      "14:53:01.247 [INFO] Epoch: 256, Loss: 0.1331913173\n",
      "14:53:01.247 [INFO] Pruning weights (56 / 62)\n",
      "14:53:01.280 [INFO] Shed 8.721426274860278e-05 weight\n",
      "14:53:01.292 [INFO] Constructed symbolic model\n",
      "14:53:01.342 [INFO] Constructed loss equation\n",
      "14:53:01.456 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:02.402 [INFO] Epoch: 1, Loss: 0.1467897594\n",
      "14:53:02.616 [INFO] Epoch: 10, Loss: 0.1474009305\n",
      "14:53:02.835 [INFO] Epoch: 20, Loss: 0.1424160749\n",
      "14:53:03.610 [INFO] Epoch: 30, Loss: 0.1299408972\n",
      "14:53:03.320 [INFO] Epoch: 40, Loss: 0.1361508667\n",
      "14:53:03.569 [INFO] Epoch: 50, Loss: 0.1436057091\n",
      "14:53:03.795 [INFO] Epoch: 60, Loss: 0.1357630491\n",
      "14:53:04.480 [INFO] Epoch: 70, Loss: 0.1456481367\n",
      "14:53:04.295 [INFO] Epoch: 80, Loss: 0.1421090811\n",
      "14:53:04.560 [INFO] Epoch: 90, Loss: 0.1400660723\n",
      "14:53:04.794 [INFO] Epoch: 100, Loss: 0.1313531250\n",
      "14:53:05.160 [INFO] Epoch: 110, Loss: 0.1366119683\n",
      "14:53:05.236 [INFO] Epoch: 120, Loss: 0.1307359040\n",
      "14:53:05.455 [INFO] Epoch: 130, Loss: 0.1405592859\n",
      "14:53:05.679 [INFO] Epoch: 140, Loss: 0.1379061341\n",
      "14:53:05.883 [INFO] Epoch: 150, Loss: 0.1496642232\n",
      "14:53:06.860 [INFO] Epoch: 160, Loss: 0.1389580816\n",
      "14:53:06.303 [INFO] Epoch: 170, Loss: 0.1479018033\n",
      "14:53:06.512 [INFO] Epoch: 180, Loss: 0.1361906230\n",
      "14:53:06.724 [INFO] Epoch: 190, Loss: 0.1346049011\n",
      "14:53:06.934 [INFO] Epoch: 200, Loss: 0.1361095011\n",
      "14:53:07.139 [INFO] Epoch: 210, Loss: 0.1385480016\n",
      "14:53:07.355 [INFO] Epoch: 220, Loss: 0.1356038153\n",
      "14:53:07.570 [INFO] Epoch: 230, Loss: 0.1329509020\n",
      "14:53:07.791 [INFO] Epoch: 240, Loss: 0.1454345584\n",
      "14:53:08.110 [INFO] Epoch: 250, Loss: 0.1346921027\n",
      "14:53:08.142 [INFO] Epoch: 256, Loss: 0.1408397257\n",
      "14:53:08.142 [INFO] Pruning weights (57 / 62)\n",
      "14:53:08.176 [INFO] Shed 6.893547833897173e-06 weight\n",
      "14:53:08.197 [INFO] Constructed symbolic model\n",
      "14:53:08.239 [INFO] Constructed loss equation\n",
      "14:53:08.349 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:09.222 [INFO] Epoch: 1, Loss: 0.1441732645\n",
      "14:53:09.417 [INFO] Epoch: 10, Loss: 0.1397394538\n",
      "14:53:09.640 [INFO] Epoch: 20, Loss: 0.1379158050\n",
      "14:53:09.857 [INFO] Epoch: 30, Loss: 0.1364699900\n",
      "14:53:10.770 [INFO] Epoch: 40, Loss: 0.1469693780\n",
      "14:53:10.287 [INFO] Epoch: 50, Loss: 0.1441878676\n",
      "14:53:10.502 [INFO] Epoch: 60, Loss: 0.1371404082\n",
      "14:53:10.721 [INFO] Epoch: 70, Loss: 0.1373202205\n",
      "14:53:10.935 [INFO] Epoch: 80, Loss: 0.1342999786\n",
      "14:53:11.145 [INFO] Epoch: 90, Loss: 0.1467517018\n",
      "14:53:11.361 [INFO] Epoch: 100, Loss: 0.1524737477\n",
      "14:53:11.584 [INFO] Epoch: 110, Loss: 0.1383021027\n",
      "14:53:11.805 [INFO] Epoch: 120, Loss: 0.1338272095\n",
      "14:53:12.220 [INFO] Epoch: 130, Loss: 0.1361477077\n",
      "14:53:12.234 [INFO] Epoch: 140, Loss: 0.1306021363\n",
      "14:53:12.457 [INFO] Epoch: 150, Loss: 0.1445661634\n",
      "14:53:12.677 [INFO] Epoch: 160, Loss: 0.1347832084\n",
      "14:53:12.897 [INFO] Epoch: 170, Loss: 0.1366086751\n",
      "14:53:13.130 [INFO] Epoch: 180, Loss: 0.1395815462\n",
      "14:53:13.351 [INFO] Epoch: 190, Loss: 0.1385977864\n",
      "14:53:13.573 [INFO] Epoch: 200, Loss: 0.1402465403\n",
      "14:53:13.798 [INFO] Epoch: 210, Loss: 0.1435041428\n",
      "14:53:14.159 [INFO] Epoch: 220, Loss: 0.1324312836\n",
      "14:53:14.426 [INFO] Epoch: 230, Loss: 0.1384230107\n",
      "14:53:14.662 [INFO] Epoch: 240, Loss: 0.1337233335\n",
      "14:53:14.932 [INFO] Epoch: 250, Loss: 0.1377025843\n",
      "14:53:15.890 [INFO] Epoch: 256, Loss: 0.1353280842\n",
      "14:53:15.900 [INFO] Pruning weights (58 / 62)\n",
      "14:53:15.128 [INFO] Shed 0.0011747423559427261 weight\n",
      "14:53:15.133 [INFO] Constructed symbolic model\n",
      "14:53:15.175 [INFO] Constructed loss equation\n",
      "14:53:15.269 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:16.820 [INFO] Epoch: 1, Loss: 0.1388668269\n",
      "14:53:16.301 [INFO] Epoch: 10, Loss: 0.1525598019\n",
      "14:53:16.530 [INFO] Epoch: 20, Loss: 0.1378037632\n",
      "14:53:16.770 [INFO] Epoch: 30, Loss: 0.1374641657\n",
      "14:53:16.989 [INFO] Epoch: 40, Loss: 0.1323462725\n",
      "14:53:17.216 [INFO] Epoch: 50, Loss: 0.1381019950\n",
      "14:53:17.443 [INFO] Epoch: 60, Loss: 0.1436873078\n",
      "14:53:17.657 [INFO] Epoch: 70, Loss: 0.1317652613\n",
      "14:53:17.874 [INFO] Epoch: 80, Loss: 0.1439512074\n",
      "14:53:18.980 [INFO] Epoch: 90, Loss: 0.1376966089\n",
      "14:53:18.315 [INFO] Epoch: 100, Loss: 0.1350028962\n",
      "14:53:18.536 [INFO] Epoch: 110, Loss: 0.1436804086\n",
      "14:53:18.752 [INFO] Epoch: 120, Loss: 0.1475732625\n",
      "14:53:18.967 [INFO] Epoch: 130, Loss: 0.1323809624\n",
      "14:53:19.189 [INFO] Epoch: 140, Loss: 0.1391237080\n",
      "14:53:19.419 [INFO] Epoch: 150, Loss: 0.1356578469\n",
      "14:53:19.634 [INFO] Epoch: 160, Loss: 0.1347363442\n",
      "14:53:19.864 [INFO] Epoch: 170, Loss: 0.1337580979\n",
      "14:53:20.850 [INFO] Epoch: 180, Loss: 0.1417232752\n",
      "14:53:20.304 [INFO] Epoch: 190, Loss: 0.1344488412\n",
      "14:53:20.520 [INFO] Epoch: 200, Loss: 0.1419076622\n",
      "14:53:20.738 [INFO] Epoch: 210, Loss: 0.1389417946\n",
      "14:53:20.957 [INFO] Epoch: 220, Loss: 0.1357416511\n",
      "14:53:21.177 [INFO] Epoch: 230, Loss: 0.1296960413\n",
      "14:53:21.392 [INFO] Epoch: 240, Loss: 0.1359332204\n",
      "14:53:21.607 [INFO] Epoch: 250, Loss: 0.1269646585\n",
      "14:53:21.737 [INFO] Epoch: 256, Loss: 0.1381956786\n",
      "14:53:21.738 [INFO] Pruning weights (59 / 62)\n",
      "14:53:21.769 [INFO] Shed 0.006319945212453604 weight\n",
      "14:53:21.774 [INFO] Constructed symbolic model\n",
      "14:53:21.791 [INFO] Constructed loss equation\n",
      "14:53:21.837 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:22.549 [INFO] Epoch: 1, Loss: 0.1320795119\n",
      "14:53:22.745 [INFO] Epoch: 10, Loss: 0.1376554668\n",
      "14:53:22.959 [INFO] Epoch: 20, Loss: 0.1239796206\n",
      "14:53:23.167 [INFO] Epoch: 30, Loss: 0.1464114338\n",
      "14:53:23.375 [INFO] Epoch: 40, Loss: 0.1348540336\n",
      "14:53:23.581 [INFO] Epoch: 50, Loss: 0.1376264989\n",
      "14:53:23.787 [INFO] Epoch: 60, Loss: 0.1354899555\n",
      "14:53:24.180 [INFO] Epoch: 70, Loss: 0.1241604760\n",
      "14:53:24.243 [INFO] Epoch: 80, Loss: 0.1358317435\n",
      "14:53:24.458 [INFO] Epoch: 90, Loss: 0.1370436400\n",
      "14:53:24.696 [INFO] Epoch: 100, Loss: 0.1313874424\n",
      "14:53:24.927 [INFO] Epoch: 110, Loss: 0.1278467178\n",
      "14:53:25.143 [INFO] Epoch: 120, Loss: 0.1274983138\n",
      "14:53:25.378 [INFO] Epoch: 130, Loss: 0.1286209226\n",
      "14:53:25.601 [INFO] Epoch: 140, Loss: 0.1294191778\n",
      "14:53:25.840 [INFO] Epoch: 150, Loss: 0.1313321292\n",
      "14:53:26.134 [INFO] Epoch: 160, Loss: 0.1371578872\n",
      "14:53:26.453 [INFO] Epoch: 170, Loss: 0.1320813000\n",
      "14:53:26.707 [INFO] Epoch: 180, Loss: 0.1409266442\n",
      "14:53:26.924 [INFO] Epoch: 190, Loss: 0.1280122846\n",
      "14:53:27.150 [INFO] Epoch: 200, Loss: 0.1458493471\n",
      "14:53:27.391 [INFO] Epoch: 210, Loss: 0.1286275536\n",
      "14:53:27.612 [INFO] Epoch: 220, Loss: 0.1246926785\n",
      "14:53:27.852 [INFO] Epoch: 230, Loss: 0.1334077418\n",
      "14:53:28.880 [INFO] Epoch: 240, Loss: 0.1313607544\n",
      "14:53:28.309 [INFO] Epoch: 250, Loss: 0.1343786567\n",
      "14:53:28.454 [INFO] Epoch: 256, Loss: 0.1276654303\n",
      "14:53:28.455 [INFO] Pruning weights (60 / 62)\n",
      "14:53:28.490 [INFO] Shed 0.007881059311330318 weight\n",
      "14:53:28.494 [INFO] Constructed symbolic model\n",
      "14:53:28.513 [INFO] Constructed loss equation\n",
      "14:53:28.570 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:29.199 [INFO] Epoch: 1, Loss: 0.1356596500\n",
      "14:53:29.406 [INFO] Epoch: 10, Loss: 0.1324222982\n",
      "14:53:29.620 [INFO] Epoch: 20, Loss: 0.1278611422\n",
      "14:53:29.835 [INFO] Epoch: 30, Loss: 0.1358654648\n",
      "14:53:30.480 [INFO] Epoch: 40, Loss: 0.1335469782\n",
      "14:53:30.262 [INFO] Epoch: 50, Loss: 0.1341985613\n",
      "14:53:30.473 [INFO] Epoch: 60, Loss: 0.1293470860\n",
      "14:53:30.690 [INFO] Epoch: 70, Loss: 0.1268931776\n",
      "14:53:30.902 [INFO] Epoch: 80, Loss: 0.1407498270\n",
      "14:53:31.110 [INFO] Epoch: 90, Loss: 0.1350469589\n",
      "14:53:31.324 [INFO] Epoch: 100, Loss: 0.1322770417\n",
      "14:53:31.548 [INFO] Epoch: 110, Loss: 0.1346771866\n",
      "14:53:31.764 [INFO] Epoch: 120, Loss: 0.1332015693\n",
      "14:53:31.983 [INFO] Epoch: 130, Loss: 0.1360153258\n",
      "14:53:32.199 [INFO] Epoch: 140, Loss: 0.1312795877\n",
      "14:53:32.419 [INFO] Epoch: 150, Loss: 0.1216953769\n",
      "14:53:32.639 [INFO] Epoch: 160, Loss: 0.1334905475\n",
      "14:53:32.859 [INFO] Epoch: 170, Loss: 0.1301862597\n",
      "14:53:33.790 [INFO] Epoch: 180, Loss: 0.1331523657\n",
      "14:53:33.303 [INFO] Epoch: 190, Loss: 0.1339533329\n",
      "14:53:33.516 [INFO] Epoch: 200, Loss: 0.1433487833\n",
      "14:53:33.720 [INFO] Epoch: 210, Loss: 0.1387354434\n",
      "14:53:33.925 [INFO] Epoch: 220, Loss: 0.1320566386\n",
      "14:53:34.137 [INFO] Epoch: 230, Loss: 0.1370418221\n",
      "14:53:34.346 [INFO] Epoch: 240, Loss: 0.1304614842\n",
      "14:53:34.579 [INFO] Epoch: 250, Loss: 0.1329862475\n",
      "14:53:34.706 [INFO] Epoch: 256, Loss: 0.1294775158\n",
      "14:53:34.707 [INFO] Pruning weights (61 / 62)\n",
      "14:53:34.738 [INFO] Shed 0.002244808943942189 weight\n",
      "14:53:34.743 [INFO] Constructed symbolic model\n",
      "14:53:34.758 [INFO] Constructed loss equation\n",
      "14:53:34.812 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:35.388 [INFO] Epoch: 1, Loss: 0.1396131068\n",
      "14:53:35.574 [INFO] Epoch: 10, Loss: 0.1347633153\n",
      "14:53:35.780 [INFO] Epoch: 20, Loss: 0.1374729872\n",
      "14:53:35.985 [INFO] Epoch: 30, Loss: 0.1347413510\n",
      "14:53:36.188 [INFO] Epoch: 40, Loss: 0.1329956949\n",
      "14:53:36.387 [INFO] Epoch: 50, Loss: 0.1301817894\n",
      "14:53:36.593 [INFO] Epoch: 60, Loss: 0.1248803586\n",
      "14:53:36.796 [INFO] Epoch: 70, Loss: 0.1365305483\n",
      "14:53:36.999 [INFO] Epoch: 80, Loss: 0.1295548230\n",
      "14:53:37.218 [INFO] Epoch: 90, Loss: 0.1275994778\n",
      "14:53:37.443 [INFO] Epoch: 100, Loss: 0.1316021681\n",
      "14:53:37.666 [INFO] Epoch: 110, Loss: 0.1264517903\n",
      "14:53:37.902 [INFO] Epoch: 120, Loss: 0.1329753995\n",
      "14:53:38.129 [INFO] Epoch: 130, Loss: 0.1356159747\n",
      "14:53:38.350 [INFO] Epoch: 140, Loss: 0.1236594170\n",
      "14:53:38.570 [INFO] Epoch: 150, Loss: 0.1274971664\n",
      "14:53:38.792 [INFO] Epoch: 160, Loss: 0.1286394596\n",
      "14:53:39.150 [INFO] Epoch: 170, Loss: 0.1386187077\n",
      "14:53:39.257 [INFO] Epoch: 180, Loss: 0.1341219842\n",
      "14:53:39.477 [INFO] Epoch: 190, Loss: 0.1243533418\n",
      "14:53:39.697 [INFO] Epoch: 200, Loss: 0.1321730018\n",
      "14:53:39.933 [INFO] Epoch: 210, Loss: 0.1281077564\n",
      "14:53:40.153 [INFO] Epoch: 220, Loss: 0.1304996014\n",
      "14:53:40.373 [INFO] Epoch: 230, Loss: 0.1322193593\n",
      "14:53:40.597 [INFO] Epoch: 240, Loss: 0.1353046000\n",
      "14:53:40.831 [INFO] Epoch: 250, Loss: 0.1347327381\n",
      "14:53:40.984 [INFO] Epoch: 256, Loss: 0.1408457458\n",
      "14:53:40.985 [INFO] Pruning weights (62 / 62)\n",
      "14:53:41.320 [INFO] Shed 0.0016059264307841659 weight\n",
      "14:53:41.360 [INFO] Constructed symbolic model\n",
      "14:53:41.490 [INFO] Constructed loss equation\n",
      "14:53:41.960 [INFO] Constructed JAXified model\n",
      "/home/paul/.local/lib/python3.10/site-packages/optax/_src/linear_algebra.py:29: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum([jnp.sum(numerics.abs_sq(x)) for x in jax.tree_leaves(updates)]))\n",
      "14:53:41.758 [INFO] Epoch: 1, Loss: 0.1287429035\n",
      "14:53:41.989 [INFO] Epoch: 10, Loss: 0.1319418550\n",
      "14:53:42.383 [INFO] Epoch: 20, Loss: 0.1391800195\n",
      "14:53:42.655 [INFO] Epoch: 30, Loss: 0.1354941726\n",
      "14:53:42.863 [INFO] Epoch: 40, Loss: 0.1246818453\n",
      "14:53:43.131 [INFO] Epoch: 50, Loss: 0.1377778798\n",
      "14:53:43.359 [INFO] Epoch: 60, Loss: 0.1359337866\n",
      "14:53:43.605 [INFO] Epoch: 70, Loss: 0.1290084422\n",
      "14:53:43.834 [INFO] Epoch: 80, Loss: 0.1257571429\n",
      "14:53:44.730 [INFO] Epoch: 90, Loss: 0.1266261041\n",
      "14:53:44.354 [INFO] Epoch: 100, Loss: 0.1223663166\n",
      "14:53:44.599 [INFO] Epoch: 110, Loss: 0.1346535385\n",
      "14:53:44.833 [INFO] Epoch: 120, Loss: 0.1335446239\n",
      "14:53:45.610 [INFO] Epoch: 130, Loss: 0.1380995661\n",
      "14:53:45.286 [INFO] Epoch: 140, Loss: 0.1358494014\n",
      "14:53:45.507 [INFO] Epoch: 150, Loss: 0.1369576454\n",
      "14:53:45.737 [INFO] Epoch: 160, Loss: 0.1337134987\n",
      "14:53:45.958 [INFO] Epoch: 170, Loss: 0.1310840845\n",
      "14:53:46.172 [INFO] Epoch: 180, Loss: 0.1320494860\n",
      "14:53:46.388 [INFO] Epoch: 190, Loss: 0.1305567920\n",
      "14:53:46.601 [INFO] Epoch: 200, Loss: 0.1385622025\n",
      "14:53:46.823 [INFO] Epoch: 210, Loss: 0.1249254197\n",
      "14:53:47.500 [INFO] Epoch: 220, Loss: 0.1321215928\n",
      "14:53:47.276 [INFO] Epoch: 230, Loss: 0.1303372681\n",
      "14:53:47.497 [INFO] Epoch: 240, Loss: 0.1349372566\n",
      "14:53:47.710 [INFO] Epoch: 250, Loss: 0.1308912486\n",
      "14:53:47.844 [INFO] Epoch: 256, Loss: 0.1222827286\n",
      "14:53:47.862 [INFO] Constructed symbolic model\n",
      "14:53:47.868 [INFO] Constructed loss equation\n",
      "14:53:47.893 [INFO] Constructed JAXified model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing more to prune!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$\\displaystyle - 1.053338832861 x y + 0.495143982030023 x + 0.557947342762368 y^{2} + 0.0786390291381303 y + 0.922053234446157 \\sin{\\left(0.976893961429596 y \\right)} + 0.652301847934723 \\sin{\\left(0.26658496260643 x + 0.496432423591614 \\sin{\\left(0.976893961429596 y \\right)} \\right)} - 0.294711053371429$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 0.10437565296888351\n"
     ]
    }
   ],
   "source": [
    "network, best, loss_histories = run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1.053338832861 x y + 0.495143982030023 x + 0.557947342762368 y^{2} + 0.0786390291381303 y + 0.922053234446157 \\sin{\\left(0.976893961429596 y \\right)} + 0.652301847934723 \\sin{\\left(0.26658496260643 x + 0.496432423591614 \\sin{\\left(0.976893961429596 y \\right)} \\right)} - 0.294711053371429\n"
     ]
    }
   ],
   "source": [
    "prediction_best = best.model.subs(zip(best.alphas, best.W))\n",
    "print(sp.latex(prediction_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history = []\n",
    "prunepoints = []\n",
    "\n",
    "for pruneepoch in loss_histories:\n",
    "  count = 0 if len(prunepoints) == 0 else prunepoints[len(prunepoints)-1]\n",
    "  for epoch in pruneepoch:\n",
    "    loss_history += [np.average(np.array(epoch))]\n",
    "    count += 1\n",
    "  prunepoints += [count]\n",
    "\n",
    "plt.title('Epoch Avg Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xlim((0, prunepoints[len(prunepoints) - 1]))\n",
    "# plt.ylim((min(loss_history)*0.5, 2))\n",
    "plt.gcf().gca().xaxis.set_major_locator(plt.MultipleLocator(2048))\n",
    "plt.gcf().gca().xaxis.set_minor_locator(plt.MultipleLocator(512))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "for prunepoint in prunepoints:\n",
    "  plt.axvline(prunepoint, color='lightgrey', linewidth=1)\n",
    "plt.plot(loss_history, linewidth=0.7)\n",
    "plt.gcf().set_dpi(150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15527494251728058"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = prediction_best\n",
    "x = network.symbols.x\n",
    "y = network.symbols.y\n",
    "d2udx2 = sp.diff(u, x, 2)\n",
    "d2udy2 = sp.diff(u, y, 2)\n",
    "\n",
    "error = x**2 * d2udx2 - y**2 * d2udy2\n",
    "error_c1 = prediction_best.subs(y, x**2) - sp.sin(x)\n",
    "error_c2 = prediction_best.subs(x, 0) - y**2\n",
    "errorlambdified = sp.lambdify([x, y], error**2 + error_c1**2 + error_c2**2, modules='jax')\n",
    "xx, yy = np.meshgrid(np.arange(*config.vars['x'].bounds, 0.01), np.arange(*config.vars['y'].bounds, 0.01))\n",
    "np.mean(errorlambdified(xx, yy)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_lambd = sp.lambdify([x, y], prediction_best, modules='jax')\n",
    "plt.imshow(u_lambd(xx, yy), origin=\"lower\")\n",
    "plt.colorbar().set_label('u', rotation=0, labelpad=10)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y', rotation=0, labelpad=10)\n",
    "plt.gcf().set_dpi(150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76a75d6e8687425ce599d3590527ed00e10d2b67147b312603dcc1dc66cf2f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
